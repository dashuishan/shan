#######################
#####
#####  CAPTER 9
#####
#######################
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 读取图像
    image = cv.imread('./images/lena.jpg')
    if image is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    # 转为灰度图像
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 生成关键点
    kps = []
    key_points = np.random.randint(0, 512, 200).reshape((100, 2))
    # print(key_points)
    # exit()
    for point in key_points:
        kps.append(cv.KeyPoint(float(point[0]), float(point[1]), 1))#这里程序中代码错误，有对于cv.KeyPoint()，前两个参数需要用float类型。

    # 绘制关键点
    image_result = cv.drawKeypoints(image, kps, None, (), cv.DRAW_MATCHES_FLAGS_DEFAULT)
    gray_result = cv.drawKeypoints(gray, kps, None, (), cv.DRAW_MATCHES_FLAGS_DEFAULT)

    # 展示结果
    cv.imshow('Color Result', image_result)
    cv.imshow('Gray Result', gray_result)
    cv.waitKey(0)
    cv.destroyAllWindows()
#################这里的角点检测实在看不出是什么，因为这些角点都是随机生成的，根本不是关键点。
import cv2 as cv
import numpy as np
import sys

if __name__ == '__main__':
    # 读取图像
    image = cv.imread('./images/lena.jpg')
    if image is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    # 转为灰度图像
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 计算Harris系数
    harris = cv.cornerHarris(gray, 2, 3, 0.04, borderType=cv.BORDER_DEFAULT)

    # 对Harris进行归一化便于进行数值比较
    harris_nor = cv.normalize(harris, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)
    harris_nor = harris_nor.astype('uint8')

    # 寻找Harris角点
    kps = []
    for i in np.argwhere(harris_nor > 125):#与125阈值相互比较，大于就保存下来。125这个值的选择，我认为与255的最大值关系较大。其实也可以该换成别的阈值。
        kps.append(cv.KeyPoint(float(i[1]), float(i[0]), 1))#则合理的cv.KeyPoint()里面是float属性。

    # 绘制角点
    result = cv.drawKeypoints(image, kps, None)

    # 展示结果
    cv.imshow('R', harris_nor)
    cv.imshow('Harris KeyPoints', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
#出Hams角点主要集中在图像人物的头发和帽子区域，因为这两个区域中线段的交点较多。
########################################################################梯度协方差矩阵的两个特征值与Harris角点判定相关。
import cv2 as cv
import numpy as np
import sys

if __name__ == '__main__':
    # 读取图像
    image = cv.imread('./images/lena.jpg')
    if image is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    # 将图像进行拷贝便于使用cv.drawKeypoints()函数绘制角点
    image1 = image.copy()

    # 转为灰度图像，并将数据类型转换为float32
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 检测Shi-Tomasi角点
    corners = cv.goodFeaturesToTrack(gray, 500, 0.01, 0.04)
    corners = np.int0(corners)

    # 绘制角点（Mode 1：使用cv.circle()函数）
    kps = []
    for corner in corners:
        x, y = corner.ravel()#ravel()方法将数组维度拉成一维数组
        cv.circle(image, (x, y), 3, (0, 255, 255), -1)

        # 将角点转化为KeyPoint类，以便于方法2的绘制
        kps.append(cv.KeyPoint(float(x), float(y), 1))

    # 绘制角点（Mode 2：使用cv.drawKeypoints()函数）
    result = cv.drawKeypoints(image1, kps, None, (), cv.DRAW_MATCHES_FLAGS_DEFAULT)

    # 展示结果
    cv.imshow('Shi-Tomasi KeyPoints(Mode 1)', image)
    cv.imshow('Shi-Tomasi KeyPoints(Mode 2)', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
#########################################Shi-Tomasi角点检测方法是cornerHarris的一种。也是矩阵梯度协方差矩阵特征值的最小值，且能够使用 cv.drawKeypoints()函数直接画出来，不需要
阈值的限定了。
import cv2 as cv
import sys

if __name__ == '__main__':
    # 读取图像
    image = cv.imread('./images/lena.jpg')
    if image is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    # 创建SURF对象
    surf = cv.xfeatures2d.SURF_create(500, 4, 3, True, False)

    # 计算SURF特征点
    kps = surf.detect(image, None)

    # 计算SURF描述子
    descriptions = surf.compute(image, kps)

    # 绘制SURF特征点
    image1 = image.copy()
    # 不含角度和大小
    image = cv.drawKeypoints(image, kps, image, ())
    # 包含角度和大小
    image1 = cv.drawKeypoints(image1, kps, image1, (), cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    # 展示结果
    cv.imshow('SURF KeyPoints', image)
    cv.imshow('SURF KeyPoints(with Angle and Size)', image1)
    cv.waitKey(0)
    cv.destroyAllWindows()
##########################################################计算SURF特征点。但是cv.xfeatures2d.SURF_create()在新的版本中并不支持调用。SURF是SIFT的变形。方便提升SIFT的效率。
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 读取图像
    image = cv.imread('./images/lena.jpg')
    if image is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    # 创建ORB对象
    orb = cv.ORB_create(500, 1.2, 8, 31, 0, 2, cv.ORB_HARRIS_SCORE, 31, 20)

    # 计算ORB特征点
    kps = orb.detect(image, None)#因为是继承的关系，所以是可以使用detect和compute方法的。

    # 计算ORB描述子
    descriptions = orb.compute(image, kps)

    # 绘制ORB特征点
    image1 = image.copy()
    # 不含角度和大小
    image = cv.drawKeypoints(image, kps, image, ())
    # 包含角度和大小
    image1 = cv.drawKeypoints(image1, kps, image1, (), cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    # 展示结果
    cv.imshow('ORB KeyPoints', image)
    cv.imshow('ORB KeyPoints(with Angle and Size)', image1)
    cv.waitKey(0)
    cv.destroyAllWindows()
##################################################ORB存在的意义是SURF和SIFT的速率太低，而且专利限制也无法进行相关运算。这个是计算两个像素点之间汉明距的方法，而SURE和SIFT是计算欧式距离的方法。
####两个整数之间的 汉明距离 指的是这两个数字对应二进制位不同的位置的数目。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像
    image1 = cv.imread('./images/box.png')
    image2 = cv.imread('./images/box_in_scene.png')
    if image1 is None or image2 is None:
        print('Failed to read box.png or box_in_scene.png.')
        sys.exit()

    # 创建ORB对象
    orb = cv.ORB_create(1000, 1.2, 8, 31, 0, 2, cv.ORB_HARRIS_SCORE, 31, 20)#暴力匹配使用的是ORB的方法，因此是可以运行的。

    # 分别计算image1，image2的ORB特征点和描述子
    kps1, des1 = orb.detectAndCompute(image1, None, None)#分别计算两张图片的ORB特征和描述子
    kps2, des2 = orb.detectAndCompute(image2, None, None)

    # 特征点匹配
    # 创建BFMatcher对象
    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)#crossCheck意思是使用了交叉检查的方法
    matches = bf.match(des1, des2)

    # 输出匹配结果中最大值和最小值
    matches_list = []
    for match in matches:
        matches_list.append(match.distance)
    max_dist = max(matches_list)
    min_dist = min(matches_list)

    # 设定阈值，筛选出合适的匹配点对
    good_matches = []
    for match in matches:
        if match.distance <= max(2.0 * min_dist, 20.0):#距离最小汉明距离的2倍和距离20中的较大值作为优化匹配的阈值对特征点对进行筛选。
            good_matches.append(match)

    # 输出匹配成功的特征点数目
    print('匹配成功的特征点数目为：{}，筛选后的特征点数目为：{}'.format(len(matches), len(good_matches)))

    # 绘制筛选前后的匹配结果
    result1 = cv.drawMatches(image1, kps1, image2, kps2, matches, None)#cv.drawMatches()画出来匹配的线段
    result2 = cv.drawMatches(image1, kps1, image2, kps2, good_matches, None)

    # 展示结果
    cv.imshow('Matches', result1)
    cv.imshow('Good Matches', result2)
    cv.waitKey(0)
    cv.destroyAllWindows()
    ################这里是暴力匹配的案例，使用的ORB的匹配 然后使用了cv.BFMatcher()对比两张图。并使用cv.drawMatches()画出匹配的线段。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像
    image1 = cv.imread('./images/box.png')
    image2 = cv.imread('./images/box_in_scene.png')
    if image1 is None or image2 is None:
        print('Failed to read box.png or box_in_scene.png.')
        sys.exit()

    # 创建ORB对象
    surf = cv.xfeatures2d.SURF_create(500, 4, 3, True, False)

    # 分别计算image1，image2的ORB特征点和描述子
    kps1, des1 = surf.detectAndCompute(image1, None, None)
    kps2, des2 = surf.detectAndCompute(image2, None, None)

    # 判断描述子数据类型，若不符合则进行数据转换
    if des1.dtype is not 'float32':
        des1 = des1.astype('float32')
    if des2.dtype is not 'float32':
        des2 = des2.astype('float32')

    # 创建FlannBasedMatcher对象
    matcher = cv.FlannBasedMatcher()

    # 特征点匹配
    matches = matcher.match(des1, des2, None)

    # 寻找距离的最大值和最小值
    matches_list = []
    for match in matches:
        matches_list.append(match.distance)
    max_dist = max(matches_list)
    min_dist = min(matches_list)

    # 设定阈值，筛选出合适的匹配点对
    good_matches = []
    for match in matches:
        if match.distance < 0.4 * max_dist:
            good_matches.append(match)

    # 输出匹配成功的特征点数目
    print('匹配成功的特征点数目为：{}，筛选后的特征点数目为：{}'.format(len(matches), len(good_matches)))

    # 绘制筛选前后的匹配结果
    result1 = cv.drawMatches(image1, kps1, image2, kps2, matches, None)
    result2 = cv.drawMatches(image1, kps1, image2, kps2, good_matches, None)

    # 展示结果
    cv.imshow('Matches', result1)
    cv.imshow('Good Matches', result2)
    cv.waitKey(0)
    cv.destroyAllWindows()
###############################只要涉及到cv.xfeatures2d()都是无法运行的。
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 读取图像
    image1 = cv.imread('./images/box.png')
    image2 = cv.imread('./images/box_in_scene.png')
    if image1 is None or image2 is None:
        print('Failed to read box.png or box_in_scene.png.')
        sys.exit()

    # 创建ORB对象
    orb = cv.ORB_create(1000, 1.2, 8, 31, 0, 2, cv.ORB_HARRIS_SCORE, 31, 20)
    # 分别计算image1，image2的ORB特征点和描述子
    kps1, des1 = orb.detectAndCompute(image1, None, None)
    kps2, des2 = orb.detectAndCompute(image2, None, None)

    # 创建BFMatcher对象
    bf = cv.BFMatcher(cv.NORM_HAMMING)
    # 暴力匹配
    matches = bf.match(des1, des2)

    # 查找最小汉明距离
    matches_list = []
    for match in matches:
        matches_list.append(match.distance)
    min_dist = min(matches_list)

    # 设定阈值，筛选出合适汉明距离的匹配点对
    good_matches = []
    for match in matches:
        if match.distance <= max(2.0 * min_dist, 20.0):
            good_matches.append(match)

    # 使用RA10选匹配结果
    # 获取关键点坐标
    src_kps = np.float32([kps1[i.queryIdx].pt for i in good_matches]).reshape(-1, 1, 2)
    dst_kps = np.float32([kps2[i.trainIdx].pt for i in good_matches]).reshape(-1, 1, 2)

    # 使用RANSAC算法筛选
    M, mask = cv.findHomography(src_kps, dst_kps, method=cv.RANSAC, ransacReprojThreshold=5.0)

    # 保存筛选后的匹配点对
    good_ransac = []
    for i in range(len(mask)):
        if mask[i] == 1:
            good_ransac.append(good_matches[i])
    
    # 绘制筛选前后的匹配结果
    result = cv.drawMatches(image1, kps1, image2, kps2, good_ransac, None)

    # 展示结果
    cv.imshow('RANSAC Matches', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
#########################################
