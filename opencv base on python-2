import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 1. 以矩阵为例
    src = np.array([[1, 2, 3, 4, 5],
                    [6, 7, 8, 9, 10],
                    [11, 12, 13, 14, 15],
                    [16, 17, 18, 19, 20],
                    [21, 22, 23, 24, 25]], dtype='float32')
    kernel1 = np.array([[1, 1, 1],
                        [1, 1, 1],
                        [1, 1, 1]], dtype='float32') / 9
    result = cv.filter2D(src, -1, kernel=kernel1)
    print('卷积前矩阵：\n{}'.format(src))
    print('卷积后矩阵：\n{}'.format(result))

    # 2. 以图像为例
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    kernel2 = np.ones((7, 7), np.float32) / 49
    result2 = cv.filter2D(img, -1, kernel=kernel2)

    # 展示结果
    cv.imshow('Origin Image', img)
    cv.imshow('Filter Result', result2)
    cv.waitKey(0)
    cv.destroyAllWindows()
    ###################################################1、这里的核为了防止卷积后过大，会把核里面的每个数字都除以和，让每个值相加等于1；2、cv.filter2D()参数中的ddepth参数是
    =-1表示输入输出为相同类型的图片。3、最后参数borderType表示像素边界外推法选择标志。
###########################################################################################
import cv2 as cv
import numpy as np


if __name__ == '__main__':
    src = np.array([[1, 2, 3, 4, 5],
                    [6, 7, 8, 9, 10],
                    [11, 12, 13, 14, 15],
                    [16, 17, 18, 19, 20],
                    [21, 22, 23, 24, 25]], dtype='float32')
    dst = cv.flip(src, -1)#这里的cv.flip(,-1)指的是先X轴旋转，再Y轴旋转
    print('原卷积模板为：\n{}'.format(src))
    print('旋转180°后的卷积模板为：\n{}'.format(dst))
####################################################################################
import cv2 as cv
import numpy as np
import sys


def add_noisy(image, n=10000):
    result = image.copy()
    w, h = image.shape[:2]
    for i in range(n):
        # 分别在宽和高的范围内生成一个随机值，模拟代表x, y坐标
        x = np.random.randint(1, w)
        y = np.random.randint(1, h)
        if np.random.randint(0, 2) == 0:
            # 生成白色噪声（盐噪声）
            result[x, y] = 0
        else:
            # 生成黑色噪声（椒噪声）
            result[x, y] = 255
    return result


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/dolphins.jpg')
    if img is None:
        print('Failed to read dolphins.jpg.')
        sys.exit()
    # 灰度图像添加椒盐噪声
    gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    gray_image_noisy = add_noisy(gray_image, 10000)
    # 彩色图像添加椒盐噪声
    color_image_noisy = add_noisy(img, 10000)

    # 展示结果
    cv.imshow("Gray Image", gray_image)
    cv.imshow("Gray Image Noisy", gray_image_noisy)
    cv.imshow("Color Image", img)
    cv.imshow("Color Image Noisy", color_image_noisy)
    cv.waitKey(0)
    cv.destroyAllWindows()
##################################################################椒盐噪声是黑的椒和白色的盐两种的组合。
import cv2 as cv
import numpy as np
import sys


def add_noise(image, mean=0, val=0.01):
    size = image.shape
    image = image / 255
    gauss = np.random.normal(mean, val ** 0.5, size)#np.random.normal中的参数size为输出的维度。
    noise = image + gauss
    return gauss, noise


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/dolphins.jpg')
    if img is None:
        print('Failed to read dolphins.jpg.')
        sys.exit()
    # 灰度图像添加高斯噪声
    gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    gray_gauss, gray_noisy_image = add_noise(gray_image)
    print(gray_gauss)
    # 彩色图像添加高斯噪声
    color_gauss, color_noisy_image = add_noise(img)

    # 展示结果
    cv.imshow("Gray Image", gray_image)
    cv.imshow("Gray Gauss Image", gray_gauss)
    cv.imshow("Gray Noisy Image", gray_noisy_image)
    cv.imshow("Color Image", img)
    cv.imshow("Color Gauss Image", color_gauss)
    cv.imshow("Color Noisy Image", color_noisy_image)
    cv.waitKey(0)
    cv.destroyAllWindows()
#########################################################################1、np.random.normal()高斯分布可以输出多个维度的数据。2、定义函数的时候设置了初始的（mean和val)所以在后面的使用函数的过程中
####就没有给出新的mean和val了。3、高斯噪声此处的平均值设置到0，但是图像像素的值在(0，255)，因此在程序中将图像归一化除以255，让高斯造成更加明显的体现出来。
####################################################################
import cv2 as cv
import sys


def my_blur(image):
    return cv.blur(image, (3, 3)), cv.blur(image, (9, 9))


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/Gray_dolphins.jpg')
    if img is None:
        print('Failed to read Gray_dolphins.jpg.')
        sys.exit()

    img_sp = cv.imread('./images/GraySaltPepperImage.jpg')
    if img_sp is None:
        print('Failed to read GraySaltPepperImage.jpg.')
        sys.exit()

    img_gauss = cv.imread('./images/GrayGaussImage.jpg')
    if img_gauss is None:
        print('Failed to read GrayGaussImage.jpg.')
        sys.exit()

    img1, img2 = my_blur(img)
    img_sp1, img_sp2 = my_blur(img_sp)
    img_gauss1, img_gauss2 = my_blur(img_gauss)

    # 展示结果
    cv.imshow('Origin Image', img)
    cv.imshow('3 * 3 Blur Image', img1)
    cv.imshow('5 * 5 Blur Image', img2)

    cv.imshow('Origin sp-noisy Image', img_sp)
    cv.imshow('3 * 3 sp-noisy Blur Image', img_sp1)
    cv.imshow('5 * 5 sp-noisy Blur Image', img_sp2)

    cv.imshow('Origin gauss-noisy Image', img_gauss)
    cv.imshow('3 * 3 gauss-noisy Blur Image', img_gauss1)
    cv.imshow('5 * 5 gauss-noisy Blur Image', img_gauss2)

    cv.waitKey(0)
    cv.destroyAllWindows()
##########################################################################cv.blur()blur英文的意思是模糊。在实际中就是没有180度旋转的卷积运算。k值做了自动的归一化处理，真个函数处理后，从表面看来没有使图片更加清晰。
import numpy as np
import sys


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/equalLena.png', cv.IMREAD_ANYDEPTH)
    if img is None:
        print('Failed to read equalLena.png.')
        sys.exit()

    # 验证方框滤波算法的数组矩阵
    points = np.array([[1, 2, 3, 4, 5],
                       [6, 7, 8, 9, 10],
                       [11, 12, 13, 14, 15],
                       [16, 17, 18, 19, 20],
                       [21, 22, 23, 24, 25]], dtype='float32')

    # 将图像转为float32类型的数据
    img_32 = img.astype('float32')
    img_32 /= 255.0

    # 方框滤波cv.boxFilter()和cv.sqrBoxFilter()
    # 进行归一化
    img_box_norm = cv.boxFilter(img, -1, (3, 3), anchor=(-1, -1), normalize=True)
    # 不进行归一化
    img_box = cv.boxFilter(img, -1, (3, 3), anchor=(-1, -1), normalize=False)

    # 进行归一化
    points_sqr_norm = cv.sqrBoxFilter(points, -1, (3, 3), anchor=(-1, -1),
                                      normalize=True, borderType=cv.BORDER_CONSTANT)
    img_sqr_norm = cv.sqrBoxFilter(img, -1, (3, 3), anchor=(-1, -1),
                                    normalize=True, borderType=cv.BORDER_CONSTANT)
    # 不进行归一化
    points_sqr = cv.sqrBoxFilter(points, -1, (3, 3), anchor=(-1, -1),
                                 normalize=False, borderType=cv.BORDER_CONSTANT)
    print(points_sqr)
    print(points_sqr_norm)
    # 展示图像处理结果
    cv.imshow('Result(cv.boxFilter() NORM)', img_box_norm)
    cv.imshow('Result(cv.boxFilter()', img_box)
    cv.imshow('Result(cv.sqrBoxFilter() NORM', img_sqr_norm / np.max(img_sqr_norm))
    cv.waitKey(0)
    cv.destroyAllWindows()
####################################################分别使用CV.sqrBoxFilter()和CV.boxFilter()两个函数进行图像滤波，如果不归一化从结果看来图像很容易呈现曝光过度的现象，失去了很多细节。
####不明白这里的 img_32 /= 255.0,如果我不用的话，显示的图像也是差不多的效果。
######################################################################################
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/Gray_dolphins.jpg', cv.IMREAD_ANYDEPTH)
    img_gauss = cv.imread('./images/GrayGaussImage.jpg', cv.IMREAD_ANYDEPTH)
    img_salt = cv.imread('./images/GraySaltPepperImage.jpg', cv.IMREAD_ANYDEPTH)
    if img is None or img_gauss is None or img_salt is None:
        print('Failed to read Gray_dolphins.jpg or GrayGaussImage.jpg or GraySaltPepperImage.jpg.')
        sys.exit()

    # 分别对上述图像进行高斯滤波，后面的数字代表滤波器尺寸
    result_5 = cv.GaussianBlur(img, (5, 5), 10, 20)
    result_9 = cv.GaussianBlur(img, (9, 9), 10, 20)
    result_5_gauss = cv.GaussianBlur(img_gauss, (5, 5), 10, 20)
    result_9_gauss = cv.GaussianBlur(img_gauss, (9, 9), 10, 20)
    result_5_salt = cv.GaussianBlur(img_salt, (5, 5), 10, 20)
    result_9_salt = cv.GaussianBlur(img_salt, (9, 9), 10, 20)

    # 展示结果
    cv.imshow('Origin img', img)
    cv.imshow('Result img 5*5', result_5)
    cv.imshow('Result img 9*9', result_9)
    cv.imshow('Origin img_gauss', img_gauss)
    cv.imshow('Result img_gauss 5*5', result_5_gauss)
    cv.imshow('Result img_gauss 9*9', result_9_gauss)
    cv.imshow('Origin img_salt', img_salt)
    cv.imshow('Result img_salt 5*5', result_5_salt)
    cv.imshow('Result img_salt 9*9', result_9_salt)
    cv.waitKey(0)
    cv.destroyAllWindows()
##################################################在均值滤波中可以看到其实是图像经过卷积得到的结果，这样的图像是变得更加模糊了，这就是神经卷积网络的基础。还有需要思考的问题是高频和低频
##################只是相对物理滤波器而言，那么数字滤波器哪里来的高频和低频呢。另外高斯滤波依然会把图像变得更加模糊。
import cv2 as cv
import numpy as np
import sys

if __name__ == '__main__':
    # 验证滤波算法的数据矩阵
    data = np.array([[1, 2, 3, 4, 5],
                    [6, 7, 8, 9, 10],
                    [11, 12, 13, 14, 15],
                    [16, 17, 18, 19, 20],
                    [21, 22, 23, 24, 25]], dtype='float32')

    # 构建X方向、Y方向和联合滤波器
    a = np.array([[-1], [3], [-1]])
    b = a.reshape((1, 3))
    ab = a * b
    print(f"ab是{ab}")
    # 验证高斯滤波的可分离性
    gaussX = cv.getGaussianKernel(3, 1)#cv.getGaussianKernel()用来生成指定大小的高斯滤波器，将生成结果放在维度为ksize*1得ndarray数组对象中并返回。
    #3 是ksize参数，高斯滤波器得半径。1是高斯滤波的标准差。
    gauss_data = cv.GaussianBlur(data, (3, 3), 1, None, 1, cv.BORDER_CONSTANT)
    gauss_data_XY = cv.sepFilter2D(data, -1, gaussX, gaussX, None, (-1, -1), 0, cv.BORDER_CONSTANT)
    print('采用cv.GaussianBlur方式：\n{}'.format(gauss_data))
    print('采用cv.sepFilter2D方式：\n{}'.format(gauss_data_XY))

    # 线性滤波的可分离性
    data_Y = cv.filter2D(data, -1, a, None, (-1, -1), 0, cv.BORDER_CONSTANT)
    data_YX = cv.filter2D(data_Y, -1, b, None, (-1, -1), 0, cv.BORDER_CONSTANT)
    data_XY = cv.filter2D(data, -1, ab, None, (-1, -1), 0, cv.BORDER_CONSTANT)
    data_XY_sep = cv.sepFilter2D(data, -1, b, b, None, (-1, -1), 0, cv.BORDER_CONSTANT)
    print('data_Y=\n{}'.format(data_Y))
    print('data_YX=\n{}'.format(data_YX))
    print('data_XY=\n{}'.format(data_XY))
    print('data_XY_sep=\n{}'.format(data_XY_sep))

    # 对图像进行分离操作
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    img_Y = cv.filter2D(img, -1, a, None, (-1, -1), 0, cv.BORDER_CONSTANT)
    img_YX = cv.filter2D(img_Y, -1, b, None, (-1, -1), 0, cv.BORDER_CONSTANT)
    img_XY = cv.filter2D(img, -1, ab, None, (-1, -1), 0, cv.BORDER_CONSTANT)

    # 展示结果
    cv.imshow('Origin', img)
    cv.imshow('img Y', img_Y)
    cv.imshow('img YX', img_YX)
    cv.imshow('img XY', img_XY)
    cv.waitKey(0)
    cv.destroyAllWindows()
################################################使用filter2D()的X和Y轴的高斯滤波后，图像得到了更加清晰的展示。为什么呢？虽然这里也是使用了高斯滤波，但是呈现出来不同的特征。
#########################################cv.sepFilter2D(cv.getGaussianKernel)和一个cv.GaussianBlur()是等价的效果。
#######################################data_YX，data_XY，data_XY_sep都是相同的，线性滤波具备可分离的特点。
import cv2 as cv
import sys
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/ColorSaltPepperImage.jpg', cv.IMREAD_ANYCOLOR)
    gray = cv.imread('./images/GraySaltPepperImage.jpg', cv.IMREAD_ANYCOLOR)
    if img is None or gray is None:
        print('Failed to read ColorSaltPepperImage.jpg or ColorSaltPepperImage.jpg.')
        sys.exit()

    # 分别对含有椒盐噪声的彩色和灰度图像进行中值滤波，后面的数字代表滤波器尺寸
    img_3 = cv.medianBlur(img, 3)
    gray_3 = cv.medianBlur(gray, 3)
    # 加载滤波器尺寸，图像会变模糊
    img_9 = cv.medianBlur(img, 9)
    gray_9 = cv.medianBlur(gray, 9)

    # 展示结果
    cv.imshow('Origin img', img)
    cv.imshow('img 3*3', img_3)
    cv.imshow('img 9*9', img_9)
    cv.imshow('Origin gray', gray)
    cv.imshow('gray 3*3', gray_3)
    cv.imshow('gray 9*9', gray_9)
    cv.waitKey(0)
    cv.destroyAllWindows()
##################################################非线性的中值滤波对噪声具有更好的抑制作用，同时在一定的条件下，中值滤波对图像的边缘信息保护得更好，可以避免图像细节的模糊。但是如果KSIZE过大也会造成图像模糊问题。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像face1.png和face2.png
    image1 = cv.imread('./images/face1.png', cv.IMREAD_ANYCOLOR)
    image2 = cv.imread('./images/face2.png', cv.IMREAD_ANYCOLOR)
    if image1 is None or image2 is None:
        print('Failed to read face1.png or face2.png.')
        sys.exit()

    # 验证不同滤波器直径的滤波效果
    res1 = cv.bilateralFilter(image1, 9, 50, 25 / 2)
    res2 = cv.bilateralFilter(image1, 25, 50, 25 / 2)

    # 验证不同标准差值的滤波效果
    res3 = cv.bilateralFilter(image2, 9, 9, 9)
    res4 = cv.bilateralFilter(image2, 9, 200, 200)

    # 展示结果
    cv.imshow('Origin_image1', image1)
    cv.imshow('Origin_image2', image2)
    cv.imshow('Result1', res1)
    cv.imshow('Result2', res2)
    cv.imshow('Result3', res3)
    cv.imshow('Result4', res4)

    cv.waitKey(0)
    cv.destroyAllWindows()
################################################################双边滤波是两个滤波器功能的叠加 分别是空间滤波器和值域滤波器图像像素灰度值相似性的滤波器。
##############################cv.bilateralFilter(image2, 9, 200, 200)这里的9是滤波器的滤波器的大小，200，200分别是颜色空间滤波器的标准差，空间坐标中滤波器的标准差。
#########################################双边滤波具有美颜的效果。
import cv2 as cv
import numpy as np
import sys

if __name__ == '__main__':
    # 读取图像equalLena.png
    image = cv.imread('./images/equalLena.png', cv.IMREAD_ANYCOLOR)
    if image is None:
        print('Failed to read equalLena.png.')
        sys.exit()

    # 创建边缘检测滤波器
    kernel1 = np.array([1, -1])
    kernel2 = np.array([1, 0, -1])
    kernel3 = kernel2.reshape((3, 1))
    kernel4 = np.array([1, 0, 0, -1]).reshape((2, 2))
    kernel5 = np.array([0, -1, 1, 0]).reshape((2, 2))

    # 检测图像边缘
    # 以[1, -1]检测水平方向边缘
    res1 = cv.filter2D(image, cv.CV_16S, kernel1)
    res1 = cv.convertScaleAbs(res1)
    # 以[1, 0, -1]检测水平方向边缘
    res2 = cv.filter2D(image, cv.CV_16S, kernel2)
    res2 = cv.convertScaleAbs(res2)
    # 以[1, 0, -1]检测垂直方向边缘
    res3 = cv.filter2D(image, cv.CV_16S, kernel3)
    res3 = cv.convertScaleAbs(res3)
    # 整幅图像边缘
    res = res2 + res3
    # 检测由左上到右下方向边缘
    res4 = cv.filter2D(image, cv.CV_16S, kernel4)
    res4 = cv.convertScaleAbs(res4)
    # 检测由右上到左下方向边缘
    res5 = cv.filter2D(image, cv.CV_16S, kernel5)
    res5 = cv.convertScaleAbs(res5)

    # 展示结果
    cv.imshow('Result1', res1)
    cv.imshow('Result2', res2)
    cv.imshow('Result3', res3)
    cv.imshow('Result', res)
    cv.imshow('Result4', res4)
    cv.imshow('Result5', res5)
    cv.waitKey(0)
    cv.destroyAllWindows()
#######################################################cv.convertScaleAbs()处理之后对矩阵中所有数据取绝对值。这样就把边缘处的轮廓求出来了。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像equalLena.png
    image = cv.imread('./images/equalLena.png', cv.IMREAD_ANYDEPTH)
    if image is None:
        print('Failed to read equalLena.png.')
        sys.exit()

    # X方向一阶边缘
    result_X = cv.Sobel(image, cv.CV_16S, 1, 0, 3)
    result_X = cv.convertScaleAbs(result_X)
    # Y方向一阶边缘
    result_Y = cv.Sobel(image, cv.CV_16S, 0, 1, 3)
    result_Y = cv.convertScaleAbs(result_Y)
    # 整幅图像的一阶边缘
    result_XY = result_X + result_Y

    # 显示结果
    cv.imshow('Result_X', result_X)
    cv.imshow('Result_Y', result_Y)
    cv.imshow('Result_XY', result_XY)
    cv.waitKey(0)
    cv.destroyAllWindows()
#######################################################这是sobel算子来得到图形边缘的方法，sobel讲滤波矩阵的ksize由(ksize,)变成了(ksize,ksize)类型。x方向一阶检测算子为
[-1,0,1  y方向的一阶算子为[-1 -2 -1
-2 0 2                    0 0  0
-1 0 1]                   1 2  1]
####这个sobel依然是先求x边缘 然后求y边缘，组后x+y。我这里使用了cv.Sobel(image, cv.CV_16S, 1, 1, 3)我想把x,y一起做矩阵变换，但是图片并没有呈现出很好的轮廓效果。
###########################################################
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像equalLena.png
    image = cv.imread('./images/equalLena.png', cv.IMREAD_ANYDEPTH)
    if image is None:
        print('Failed to read equalLena.png.')
        sys.exit()

    # X方向一阶边缘
    result_X = cv.Scharr(image, cv.CV_16S, 1, 0)
    result_X = cv.convertScaleAbs(result_X)
    # Y方向一阶边缘
    result_Y = cv.Scharr(image, cv.CV_16S, 0, 1)
    result_Y = cv.convertScaleAbs(result_Y)
    # 整幅图像的一阶边缘
    result_XY = result_X + result_Y

    # 显示结果
    cv.imshow('Result_X', result_X)
    cv.imshow('Result_Y', result_Y)
    cv.imshow('Result_XY', result_XY)
    cv.waitKey(0)
    cv.destroyAllWindows()
##########################################################################################cv.Scharr()是sobel算子中的升级性，提供了更多的图像细节。
import cv2 as cv


if __name__ == '__main__':
    # 一阶X方向Sobel算子
    sobel_x1, sobel_y1 = cv.getDerivKernels(1, 0, 3)
    sobel_X1 = sobel_y1 * sobel_x1.T
    print('一阶X方向Sobel算子：\n{}'.format(sobel_X1))

    # 二阶X方向Sobel算子
    sobel_x2, sobel_y2 = cv.getDerivKernels(2, 0, 5)
    sobel_X2 = sobel_y2 * sobel_x2.T
    print('二阶X方向Sobel算子：\n{}'.format(sobel_X2))

    # 三阶X方向Sobel算子
    sobel_x3, sobel_y3 = cv.getDerivKernels(3, 0, 7)
    sobel_X3 = sobel_y3 * sobel_x3.T
    print('三阶X方向Sobel算子：\n{}'.format(sobel_X3))

    # X方向Scharr算子
    scharr_x, scharr_y = cv.getDerivKernels(1, 0, cv.FILTER_SCHARR)
    scharr_X = scharr_y * scharr_x.T
    print('X方向Scharr算子：\n{}'.format(scharr_X))
##################################这里需要重新对sobel算子进行学习，sobel算子通过离散微分方法求图像边缘的边缘检测算子，步骤分别是1、提取X方向的边缘，2、提取y方向的边缘。3、将cv.convertScaleAbs（X+Y）
#####################################sobel可以取多阶来进行边缘的提取。。cv.getDerivKernels()就是找到cv.sobel和CV.Scharr边缘检测滤波器的方法。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像equalLena.png
    image = cv.imread('./images/equalLena.png', cv.IMREAD_ANYDEPTH)
    if image is None:
        print('Failed to read equalLena.png.')
        sys.exit()

    # 未滤波提取图像边缘
    result = cv.Laplacian(image, cv.CV_16S, ksize=3, scale=1, delta=0)
    result = cv.convertScaleAbs(result)
    # 滤波后提取图像边缘
    result_gauss = cv.GaussianBlur(image, (3, 3), 5, 0)
    result_gauss = cv.Laplacian(result_gauss, cv.CV_16S, ksize=3, scale=1, delta=0)
    result_gauss = cv.convertScaleAbs(result_gauss)

    # 显示结果
    cv.imshow('Result', result)
    cv.imshow('Result_Gauss', result_gauss)
    cv.waitKey(0)
    cv.destroyAllWindows()
###########################################sobel算子和scharr算子都是在X和Y轴分别取值，然后合并两个方向得到滤波器
############拉普拉斯算子则是从不同方向来求解这个滤波器，同时拉普拉斯滤波器对高斯噪声过敏，需要先进行高斯滤波。然后再拉普拉斯变换。
import cv2 as cv
import sys

if __name__ == '__main__':
    # 读取图像equalLena.png
    image = cv.imread('./images/equalLena.png', cv.IMREAD_ANYDEPTH)
    if image is None:
        print('Failed to read equalLena.png.')
        sys.exit()

    # 大阈值检测图像边缘
    result_high = cv.Canny(image, 100, 200, apertureSize=3)
    # 小阈值检测图像边缘
    result_low = cv.Canny(image, 20, 40, apertureSize=3)
    # 高斯模糊后检测图像边缘
    result_gauss = cv.GaussianBlur(image, (3, 3), 5)
    result_gauss = cv.Canny(result_gauss, 100, 200, apertureSize=3)

    # 显示结果
    cv.imshow('Result_high', result_high)
    cv.imshow('Result_low', result_low)
    cv.imshow('Result_gauss', result_gauss)
    cv.waitKey(0)
    cv.destroyAllWindows()
########################canny算法是边缘检测中的集大成者，是最优秀的边缘检测算法之一。能识别图像中的弱边缘和强边缘，并结合强弱边缘的位置关系综合给出图像的边缘信息。
######CAPTER 6
######
#####################################
import cv2 as cv
import numpy as np
import sys
if __name__ == '__main__':
    # 创建矩阵，用于求像素之间的距离
    array = np.array([[1, 1, 1, 1, 1],
                      [1, 1, 1, 1, 1],
                      [1, 1, 0, 1, 1],
                      [1, 1, 1, 1, 1],
                      [1, 1, 1, 1, 1]], dtype='uint8')
    # 分别计算街区距离、欧氏距离和棋盘距离
    dst_L1 = cv.distanceTransform(array, cv.DIST_L1, cv.DIST_MASK_3)#cv.DIST_L1是指街区距离，cv.DIST_MASK_3掩膜
    dst_L2 = cv.distanceTransform(array, cv.DIST_L2, cv.DIST_MASK_5)#cv.DIST_L2是指欧式距离，cv.DIST_MASK_5掩膜表示精确计算。
    dst_C = cv.distanceTransform(array, cv.DIST_C, cv.DIST_MASK_3)#cv.DIST_C是棋盘距离，

    # 对图像进行读取
    rice = cv.imread('./images/rice.png', cv.IMREAD_GRAYSCALE)
    if rice is None:
        print('Failed to read rice.png.')
        sys.exit()

    # 将图像转成二值图像，同时将黑白区域互换
    rice_BW = cv.threshold(rice, 50, 255, cv.THRESH_BINARY)
    rice_BW_INV = cv.threshold(rice, 50, 255, cv.THRESH_BINARY_INV)

    # 图像距离变换
    dst_rice_BW = cv.distanceTransform(rice_BW[1], 1, 3, dstType=cv.CV_32F)#这里使用的是rice_BW[1]，是因为在cv.threshold()返回值为retval,dst。所以list[1]才是图片
    dst_rice_BW_INV = cv.distanceTransform(rice_BW_INV[1], 1, 3, dstType=cv.CV_8U)

    # 展示矩阵距离计算结果
    print('街区距离：\n{}'.format(dst_L1))
    print('欧氏距离：\n{}'.format(dst_L2))
    print('棋盘距离：\n{}'.format(dst_C))
    print(f'rice_BW是{rice_BW}')
    # print(f'rice_BW_INV是{rice_BW_INV}')

    # 展示二值化、黑白互换后的图像及距离变换结果
    cv.imshow('rice_BW', rice_BW[1])
    cv.imshow('rice_BW_INV', rice_BW_INV[1])
    cv.imshow('dst_rice_BW', dst_rice_BW)
    cv.imshow('dst_rice_BW_INV', dst_rice_BW_INV)

    cv.waitKey(0)
    cv.destroyAllWindows()
####################################################这里的cv.distanceTransform()的距离变换并没有改变图像的显示。CV_32F倒是显示出来和以前一摸一样的图像。
import cv2 as cv
import numpy as np
import sys


def generate_random_color():
    """输出不同的颜色"""
    return np.random.randint(0, 256, 3)


def fill_color(img1, n, img2):
    h, w = img1.shape
    res = np.zeros((h, w, 3), img1.dtype)
    # 生成随机颜色
    random_color = {}
    for c in range(1, n):
        random_color[c] = generate_random_color()
    # 为不同的连通域填色
    for i in range(h):
        for j in range(w):
            item = img2[i][j]
            if item == 0:#0表示黑色的。
                pass
            else:
                print(item)
                res[i, j, :] = random_color[item]
    return res

if __name__ == '__main__':
    # 对图像进行读取，并转换为灰度图像
    rice = cv.imread('./images/rice.png', cv.IMREAD_GRAYSCALE)
    if rice is None:
        print('Failed to read rice.png.')
        sys.exit()

    # 将图像转成二值图像
    rice_BW = cv.threshold(rice, 50, 255, cv.THRESH_BINARY)
    # 统计连通域
    count, dst = cv.connectedComponents(rice_BW[1], ltype=cv.CV_16U)#count是指返回的统计连通域的数量，这里得出的值是27，但在fill_color（)函数种，生成随机颜色时range的范围是从1开始的。
    print(dst)
    # 以不同颜色标记出不同的连通域
    result = fill_color(rice, count, dst)

    # 展示结果
    cv.imshow('Origin', rice)
    cv.imshow('Result', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
##########################################################################使用cv.connectedComponents（）返回两个参数 count, dst,这两个参数一个是连通的个数，另外一个连通的区域img[i,j]都赋值为连通区的数值 25，26....之类的值了。
##################
import cv2 as cv
import numpy as np
import sys


def generate_random_color():
    return np.random.randint(0, 256, 3)


def fill_color(img1, n, img2):
    h, w = img1.shape
    res = np.zeros((h, w, 3), img1.dtype)
    # 生成随机颜色
    random_color = {}
    for c in range(1, n):
        random_color[c] = generate_random_color()
    # 为不同的连通域填色
    for i in range(h):
        for j in range(w):
            item = img2[i][j]
            if item == 0:
                pass
            else:
                res[i, j, :] = random_color[item]
    return res


def mark(img, n, stat, cent):
    for i in range(1, n):
        # 绘制中心点
        cv.circle(img, (int(cent[i, 0]), int(cent[i, 1])), 2, (0, 255, 0), -1)
        # 绘制矩形边框
        color = list(map(lambda x: int(x), generate_random_color()))#map()用法用法：map(function, iterable, …)
        # ，会根据提供的函数对指定的序列做映射,将func作用于参数iterable中的每一个元素，并将所有的调用的结果作为一个list返回。
        #map(square,[1,2,3,4,5])结果是[1,4,9,16,25]
        #通过使用lambda匿名函数的方法使用map()函数：
        #print(list(map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])))  # Python中map和lambda的套用无法直接显示，需要加list
        # 结果如下：[3, 7, 11, 15, 19]

        print(color)
        cv.rectangle(img,
                     (stat[i, 0], stat[i, 1]),
                     (stat[i, 0] + stat[i, 2], stat[i, 1] + stat[i, 3]),
                     color)
        # 标记数字
        font = cv.FONT_HERSHEY_SIMPLEX
        cv.putText(img,
                   str(i),
                   (int(cent[i, 0] + 5), int(cent[i, 1] + 5)),
                   font,
                   0.5,
                   (0, 0, 255),
                   1)


if __name__ == '__main__':
    # 对图像进行读取，并转换为灰度图像
    rice = cv.imread('./images/rice.png', cv.IMREAD_GRAYSCALE)
    if rice is None:
        print('Failed to read rice.png.')
        sys.exit()

    # 将图像转成二值图像
    rice_BW = cv.threshold(rice, 50, 255, cv.THRESH_BINARY)
    # 统计连通域
    count, dst, stats, centroids = cv.connectedComponentsWithStats(rice_BW[1], ltype=cv.CV_16U)#centroids是每个连通域的质心坐标。centroids[i,0]和centroids[i,1]跟别读取第i个连通域之心的x坐标和y坐标。
    # 为不同的连通域填色
    result = fill_color(rice, count, dst)

    # 绘制外接矩形及中心点，并进行标记
    mark(result, count, stats, centroids)

    # 输出每个连通域的面积
    for s in range(1, count):
        print('第 {} 个连通域的面积为：{}'.format(s, stats[s, 4]))#stats[,4]的意思是Cv.CC_STAT_AREA，连通域的面积。
    # 展示结果
    cv.imshow('Origin', rice)
    cv.imshow('Result', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
###################################################### count, dst, stats, centroids = cv.connectedComponentsWithStats()这里将的是使用连通区域的函数来计数和画图等操作。
import cv2 as cv
import numpy as np
import sys


def generate_random_color():
    return np.random.randint(0, 256, 3)


def fill_color(img1, n, img2):#img1是原始图像，img2是二值化然后求连通区域后的图像
    h, w = img1.shape
    res = np.zeros((h, w, 3), img1.dtype)#有疑问的是：整形数据不应该是int吗？浮点型数据不应该是float吗？解答：int32、float64是Numpy库自己的一套数据类型。
    # 生成随机颜色
    random_color = {}
    for c in range(1, n):
        random_color[c] = generate_random_color()
    # 为不同的连通域填色
    for i in range(h):#这个循环利用item的值相同，将所有连通区域。
        for j in range(w):
            item = img2[i][j]
            if item == 0:
                pass
            else:
                res[i, j, :] = random_color[item]
    return res


def mark(img, n, stat, cent):
    for i in range(1, n):
        # 绘制中心点
        cv.circle(img, (int(cent[i, 0]), int(cent[i, 1])), 2, (0, 255, 0), -1)
        # 绘制矩形边框
        color = list(map(lambda x: int(x), generate_random_color()))#标准写法
        cv.rectangle(img,
                     (stat[i, 0], stat[i, 1]),
                     (stat[i, 0] + stat[i, 2], stat[i, 1] + stat[i, 3]),
                     color)
        # 标记数字
        font = cv.FONT_HERSHEY_SIMPLEX
        cv.putText(img,
                   str(i),
                   (int(cent[i, 0] + 5), int(cent[i, 1] + 5)),
                   font,
                   0.5,
                   (0, 0, 255),
                   1)


if __name__ == '__main__':
    # 生成待腐蚀图像image
    image = np.array([[0, 0, 0, 0, 255, 0],
                     [0, 255, 255, 255, 255, 255],
                     [0, 255, 255, 255, 255, 0],
                     [0, 255, 255, 255, 255, 0],
                     [0, 255, 255, 255, 255, 0],
                     [0, 0, 0, 0, 0, 0]], dtype='uint8')
    # 分别读取黑背景和白背景图
    black = cv.imread('./images/LearnCV_black.png', cv.IMREAD_GRAYSCALE)
    if black is None:
        print('Failed to read LearnCV_black.png.')
        sys.exit()
    white = cv.imread('./images/LearnCV_white.png', cv.IMREAD_GRAYSCALE)
    if white is None:
        print('Failed to read LearnCV_white.png.')
        sys.exit()
    # 读取米粒图像
    rice = cv.imread('./images/rice.png', cv.IMREAD_GRAYSCALE)
    if rice is None:
        print('Failed to read rice.png.')
        sys.exit()

    # 生成两种结构元素：0表示structure1为矩形结构，1表示structure2为十字结构
    structure1 = cv.getStructuringElement(0, (3, 3))
    structure2 = cv.getStructuringElement(1, (3, 3))

    # 对img1进行腐蚀
    erode_image = cv.erode(image, structure2)
    # 分别对黑背景和白背景图像进行矩形结构和十字结构元素腐蚀
    erode_black_1 = cv.erode(black, structure1)
    erode_black_2 = cv.erode(black, structure2)
    erode_white_1 = cv.erode(white, structure1)
    erode_white_2 = cv.erode(white, structure2)

    # 将图像rice转为二值图像
    rice_BW = cv.threshold(rice, 50, 255, cv.THRESH_BINARY)
    # 对图像进行矩形结构元素腐蚀
    erode_riceBW = cv.erode(rice_BW[1], structure1)#这里用的十字腐蚀
    # 统计连通域
    count, dst, stats, centroids = cv.connectedComponentsWithStats(rice_BW[1], ltype=cv.CV_16U)
    erode_count, erode_dst, erode_stats, erode_centroids = \
        cv.connectedComponentsWithStats(erode_riceBW, ltype=cv.CV_16U)
    # 为不同的连通域填色
    erode_rice = rice#注意这里的赋值操作，其实还是在原图上操作。
    rice = fill_color(rice, count, dst)
    erode_rice = fill_color(erode_rice, erode_count, erode_dst)
    # 绘制外接矩形及中心点，并进行标记
    mark(rice, count, stats, centroids)
    mark(erode_rice, erode_count, erode_stats, erode_centroids)

    # 展示结果
    cv.namedWindow('image', 0)
    cv.namedWindow('image erode', 0)
    cv.imshow('image', image)
    cv.imshow('image erode', erode_image)
    cv.imshow('LearnCV black', black)
    cv.imshow('LearnCV black erode structure1', erode_black_1)
    cv.imshow('LearnCV black erode structure2', erode_black_2)
    cv.imshow('LearnCV white', white)
    cv.imshow('LearnCV white erode structure1', erode_white_1)
    cv.imshow('LearnCV white erode structure2', erode_white_2)
    cv.imshow('Rice Result', rice)
    cv.imshow('Rice Result erode', erode_rice)

    cv.waitKey(0)
    cv.destroyAllWindows()
#################################################################使用腐蚀cv.erode（）,主要需要弄清楚的是腐蚀就去除了rice这张图片中那些不需要的干扰，最后得到的数量更加贴近真实的数量。
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 生成待膨胀图像image
    image = np.array([[0, 0, 0, 0, 255, 0],
                      [0, 255, 255, 255, 255, 255],
                      [0, 255, 255, 255, 255, 0],
                      [0, 255, 255, 255, 255, 0],
                      [0, 255, 255, 255, 255, 0],
                      [0, 0, 0, 0, 0, 0]], dtype='uint8')
    # 分别读取黑背景和白背景图
    black = cv.imread('./images/LearnCV_black.png', cv.IMREAD_GRAYSCALE)
    if black is None:
        print('Failed to read LearnCV_black.png.')
        sys.exit()
    white = cv.imread('./images/LearnCV_white.png', cv.IMREAD_GRAYSCALE)
    if white is None:
        print('Failed to read LearnCV_white.png.')
        sys.exit()

    # 生成两种结构元素：structure1为矩形结构，structure2为十字结构
    structure1 = cv.getStructuringElement(0, (3, 3))
    structure2 = cv.getStructuringElement(1, (3, 3))

    # 对img1进行膨胀
    dilate_image = cv.dilate(image, structure2)
    # 分别对黑背景和白背景图像进行矩形结构和十字结构元素膨胀
    dilate_black_1 = cv.dilate(black, structure1)
    dilate_black_2 = cv.dilate(black, structure2)
    dilate_white_1 = cv.dilate(white, structure1)
    dilate_white_2 = cv.erode(white, structure2)
    # 比较膨胀和腐蚀的结果
    erode_black = cv.erode(black, structure1)
    result_xor = cv.bitwise_xor(erode_black, dilate_white_1)
    result_and = cv.bitwise_and(erode_black, dilate_white_1)

    # 展示结果
    cv.namedWindow('image', 0)
    cv.namedWindow('image dilate', 0)
    cv.imshow('image', image)
    cv.imshow('image dilate', dilate_image)
    cv.imshow('LearnCV black', black)
    cv.imshow('LearnCV black dilate structure1', dilate_black_1)
    cv.imshow('LearnCV black dilate structure2', dilate_black_2)
    cv.imshow('LearnCV white', white)
    cv.imshow('LearnCV white dilate structure1', dilate_white_1)
    cv.imshow('LearnCV white dilate structure2', dilate_white_2)
    cv.imshow('Result Xor', result_xor)
    cv.imshow('Result And', result_and)

    cv.waitKey(0)
    cv.destroyAllWindows()
#########################################################################cv.dilate()进行膨胀的操作。无论是膨胀还是腐蚀都是使用cv.getStructuringElement（）去得到结构元素。
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 生成二值矩阵src
    src = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 255, 255, 255, 255, 255, 255, 255, 0, 0, 255, 0],
                    [0, 255, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0],
                    [0, 255, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0],
                    [0, 255, 255, 255, 0, 255, 255, 255, 0, 0, 0, 0],
                    [0, 255, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0],
                    [0, 255, 255, 255, 255, 255, 255, 255, 0, 0, 255, 0],
                    [0, 255, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype='uint8')

    # 生成3*3矩形结构元素
    kernel = cv.getStructuringElement(0, (3, 3))

    # 对二值矩阵分别进行开运算、闭运算、梯度运算、顶帽运算、黑帽运算以及击中击不中变换
    open_src = cv.morphologyEx(src, cv.MORPH_OPEN, kernel)
    close_src = cv.morphologyEx(src, cv.MORPH_CLOSE, kernel)
    gradient_src = cv.morphologyEx(src, cv.MORPH_GRADIENT, kernel)
    tophat_src = cv.morphologyEx(src, cv.MORPH_TOPHAT, kernel)
    blackhat_src = cv.morphologyEx(src, cv.MORPH_BLACKHAT, kernel)
    hitmiss_src = cv.morphologyEx(src, cv.MORPH_HITMISS, kernel)

    # 展示二值矩阵形态学操作结果
    # cv.namedWindow('src', cv.WINDOW_NORMAL)
    # cv.imshow('src', src)
    # cv.namedWindow('Open src', cv.WINDOW_NORMAL)
    # cv.imshow('Open src', open_src)
    # cv.namedWindow('Close src', cv.WINDOW_NORMAL)
    # cv.imshow('Close src', close_src)
    # cv.namedWindow('Gradient src', cv.WINDOW_NORMAL)
    # cv.imshow('Gradient src', gradient_src)
    # cv.namedWindow('Tophat src', cv.WINDOW_NORMAL)
    # cv.imshow('Tophat src', tophat_src)
    # cv.namedWindow('Blackhat src', cv.WINDOW_NORMAL)
    # cv.imshow('Blackhat src', blackhat_src)
    # cv.namedWindow('Hitmiss src', cv.WINDOW_NORMAL)
    # cv.imshow('Hitmiss src', hitmiss_src)
    # cv.waitKey(0)

    # 读取图像keys.jpg并进行二值化
    #keys = cv.imread('./images/rice.png', cv.IMREAD_GRAYSCALE)
    keys = cv.imread('./images/keys.jpg', cv.IMREAD_GRAYSCALE)
    print(keys)
    if keys is None:
        print('Failed to read keys.jpg.')
        sys.exit()
    cv.imshow('Origin', keys)
    keys = cv.threshold(keys, 130, 255, cv.THRESH_BINARY)[1]

    # 生成5*5矩形结构元素
    kernel_keys = cv.getStructuringElement(0, (5, 5))

    # 对图像分别进行开运算、闭运算、梯度运算、顶帽运算、黑帽运算以及击中击不中变换
    open_keys = cv.morphologyEx(keys, cv.MORPH_OPEN, kernel_keys)
    close_keys = cv.morphologyEx(keys, cv.MORPH_CLOSE, kernel_keys)
    gradient_keys = cv.morphologyEx(keys, cv.MORPH_GRADIENT, kernel_keys)
    tophat_keys = cv.morphologyEx(keys, cv.MORPH_TOPHAT, kernel_keys)
    blackhat_keys = cv.morphologyEx(keys, cv.MORPH_BLACKHAT, kernel_keys)
    hitmiss_keys = cv.morphologyEx(keys, cv.MORPH_HITMISS, kernel_keys)

    # 展示图像形态学操作结果
    cv.imshow('Two-valued keys', keys)
    cv.imshow('Open keys', open_keys)
    cv.imshow('Close keys', close_keys)
    cv.imshow('Gradient keys', gradient_keys)
    cv.imshow('Tophat keys', tophat_keys)
    cv.imshow('Blackhat keys', blackhat_keys)
    cv.imshow('Hitmiss keys', hitmiss_keys)

    cv.waitKey(0)
    cv.destroyAllWindows()
####################################################################对图像分别进行开运算、闭运算、梯度运算、顶帽运算、黑帽运算以及击中击不中变换,有个坑就是cv.imshow（）只能显示有限的图片，这个图片中有很多是无法显示的。
######################################################################这么多的变化 我其实是不知道有什么用的。
import cv2 as cv
import sys

if __name__ == '__main__':
    # 对图像进行读取
    img1 = cv.imread('./images/LearnCV_black.png', cv.IMREAD_GRAYSCALE)
    if img1 is None:
        print('Failed to read LearnCV_black.png.')
        sys.exit()
    img2 = cv.imread('./images/OpenCV_4.1.png', cv.IMREAD_GRAYSCALE)
    if img2 is None:
        print('Failed to read OpenCV_4.1.png.')
        sys.exit()

    # 对图片进行细化
    thin1 = cv.ximgproc.thinning(img1, thinningType=0)
    thin2 = cv.ximgproc.thinning(img2, thinningType=0)

    # 展示结果
    cv.imshow('img1', img1)
    cv.imshow('img1_thinning', thin1)
    cv.imshow('img2', img2)
    cv.imshow('img2_thinning', thin2)

    cv.waitKey(0)
    cv.destroyAllWindows()
#####################################################这是细狗算法吗？
##############       
##############    CAPTER 7
##############
#######################################################
#cv.HoughLines()使用阈值200得到的直线多于使用300得到的直线。
import cv2 as cv
import numpy as np
import sys

def draw_line(img, lines):
    img_copy = img.copy()
    for i in range(0, len(lines)):
        rho, theta = lines[i][0][0], lines[i][0][1]#这里返回值是极化坐标中的r和theta。
        a = np.cos(theta)
        b = np.sin(theta)
        x0 = a * rho
        y0 = b * rho
        x1 = int(x0 + 1000 * (-b))
        y1 = int(y0 + 1000 * a)
        x2 = int(x0 - 1000 * (-b))
        y2 = int(y0 - 1000 * a)#x1,y1,x2,y2是和x0,y0 公式为(y1-y0)/(x1-x0)=cos(theta)/sin(theta).这里使用了1000,其实换成500 /800也是可以的。
        cv.line(img_copy, (x1, y1), (x2, y2), (255, 255, 255), 2)
    return img_copy
#详见https://blog.csdn.net/yl_best/article/details/88744997
if __name__ == '__main__':
    # 读取图像HoughLines.jpg
    image = cv.imread('./images/HoughLines.jpg')
    if image is None:
        print('Failed to read HoughLines.jpg.')
        sys.exit()
    cv.imshow('Origin', image)

    # 检测图像边缘
    image_edge = cv.Canny(image, 50, 150, 3)#直接使用canny（）没有二值化吗？
    cv.imshow('Image Edge', image_edge)

    # 分别设定不同累加器阈值进行直线检测，并显示结果
    threshold_1 = 200
    lines_1 = cv.HoughLines(image_edge, 1, np.pi / 180, threshold_1)
    try:
        img1 = draw_line(image, lines_1)
        cv.imshow('Image HoughLines({})'.format(threshold_1), img1)
    except TypeError:
        print('累加器阈值设为 {} 时，不能检测出直线.'.format(threshold_1))

    threshold_2 = 300
    lines_2 = cv.HoughLines(image_edge, 1, np.pi / 180, threshold_2)
    try:
        img2 = draw_line(image, lines_2)
        cv.imshow('Image HoughLines({})'.format(threshold_2), img2)
    except TypeError:
        print('累加器阈值设为 {} 时，不能检测出直线.'.format(threshold_2))

    cv.waitKey(0)
    cv.destroyAllWindows()
#########################################################看看看，这里专门定义了画直线的函数def draw_line(img, lines)
import cv2 as cv
import numpy as np
import sys


def draw_line(img, lines):
    img_copy = img.copy()
    for i in range(0, len(lines)):
        for x1, y1, x2, y2 in lines[i]:
            cv.line(img_copy, (x1, y1), (x2, y2), (255, 255, 255), 2)
    print(img_copy)
    return img_copy


if __name__ == '__main__':
    # 读取图像HoughLines.jpg
    image = cv.imread('./images/HoughLines.jpg')
    if image is None:
        print('Failed to read HoughLines.jpg.')
        sys.exit()
    cv.imshow('Origin', image)

    # 检测图像边缘
    image_edge = cv.Canny(image, 80, 180, 3)
    cv.imshow('Image Edge', image_edge)

    # 设置直线的最小长度
    min_line_length = 200#线段的最短长度，当检测线段的长度小于该数值时，将会被剔除。

    # 分别设定不同直线最大连接距离进行直线检测，并显示结果
    max_line_gap_1 = 5#
    lines_1 = cv.HoughLinesP(image_edge, 1, np.pi / 180, 150, minLineLength=min_line_length, maxLineGap=max_line_gap_1)

    img1 = draw_line(image, lines_1)
    # try:
    cv.imshow('Image HoughLinesP ({})'.format(max_line_gap_1), img1)
    # except TypeError:
    #     print('最大连接距离设为 {} 时，不能检测出直线.'.format(max_line_gap_1))
    print(lines_1)
    max_line_gap_2 = 20
    lines_2 = cv.HoughLinesP(image_edge, 1, np.pi / 180, 150, minLineLength=min_line_length, maxLineGap=max_line_gap_2)
    try:
        img2 = draw_line(image, lines_2)#不需要专门的设置画图函数了，更加简约。
        cv.imshow('Image HoughLinesP ({})'.format(max_line_gap_2), img2)
    except TypeError:
        print('最大连接距离设为 {} 时，不能检测出直线.'.format(max_line_gap_2))

    cv.waitKey(0)
    cv.destroyAllWindows()
###################################################################################### cv.HoughLinesP(）更实用。这里设置了不同的maxlinegap参数，表示最大连接距离。最终的结果20比5会有更多的直线被显示出来。
import cv2 as cv
import numpy as np


if __name__ == '__main__':
    # 生成float32类型的20 * 2 矩阵表示2D点集
    points = np.array([[[0.0, 369.0], [10.0, 364.0], [20.0, 358.0], [30.0, 352.0], [40.0, 346.0],
                       [50.0, 341.0], [60.0, 335.0], [70.0, 329.0], [80.0, 323.0], [90.0, 318.0],
                       [100.0, 312.0], [110, 306.0], [120.0, 300.0], [130.0, 295.0], [140.0, 289.0],
                       [150.0, 284.0], [160.0, 277.0], [170.0, 271.0], [180.0, 266.0], [190.0, 260.0]]],
                      dtype='float32')

    # 设置参数
    min_rho = 0.0                        # 最小长度
    max_rho = 360.0                      # 最大长度
    rho_step = 1                         # 离散化单位距离长度
    min_theta = 0.0                      # 最小角度，这个参数的意思是检测的直线经过原点的垂线与x轴夹角的最小值’以弧度为单位。
    max_theta = np.pi / 2.0              # 最大角度，这个参数的意思是检测的直线经过原点的垂线与x轴夹角的最大值’以弧度为单位。
    theta_step = np.pi / 180.0           # 离散化单位角度弧度

    # 进行检测
    lines = cv.HoughLinesPointSet(points, 20, 1, min_rho, max_rho, rho_step, min_theta, max_theta, theta_step)
    for item in lines:
        print('votes: {}, rho: {}, theta: {}'.format(item[0][0], item[0][1], item[0][2]))
        #看出来输出的lines包含的参数是直线权重、直线与坐标原点的距离′’以及坐标原点到直线的垂线与x轴的夹角0输出
##################################################这里实用了cv.houghLinesPointSet(),提供了能够在含有坐标的众多点中判断是否存在直线的函数.
import cv2 as cv
import numpy as np

if __name__ == '__main__':
    # 生成float32类型的20 * 2 矩阵表示2D点集
    points = np.array([[[0.0, 0.0], [10.0, 11.0], [21.0, 20.0], [30.0, 30.0], [40.0, 42.0],
                       [50.0, 50.0], [60.0, 60.0], [70.0, 70.0], [80.0, 80.0], [90.0, 92.0],
                       [100.0, 100.0], [110, 110.0], [120.0, 120.0], [136.0, 130.0], [138.0, 140.0],
                       [150.0, 150.0], [160.0, 163.0], [175.0, 170.0], [181.0, 180.0], [200.0, 190.0]]],
                      dtype='float32')

    # 设置参数
    param = 0                          # 距离模型中的数值参数C
    reps = 0.01                        # 坐标原点与直线之间的距离精度
    aeps = 0.01                        # 角度精度

    # 进行直线拟合
    line = cv.fitLine(points, cv.DIST_L1, param, reps, aeps)
    print(line[0][0])
    k = (line[1] / line[0])[0]
    x = (line[2])[0]
    y = (line[3])[0]
    print('直线斜率为：{}'.format(k))
    print('直线上一点的坐标为：({}，{})'.format(x, y))
    print('拟合直线解析式为：y = {} (x - {}) + {}'.format(k, x, y))
#############################################################################这里请注意line是一个[4,1]的list，如果取数的情况需要实用line[0][0]的操作取值，如果使用line[0]取出来的则是[0.999]的list.
import cv2 as cv
import sys


def draw_circle(img, values):
    for i in values[0, :]:
        cv.circle(img, (i[0], i[1]), i[2], (255, 0, 0), 2)
        cv.circle(img, (i[0], i[1]), 2, (0, 255, 0), 3)


if __name__ == '__main__':
    # 读取图像circles.png
    image = cv.imread('./images/circles.png')
    if image is None:
        print('Failed to read circles.png.')
        sys.exit()
    cv.imshow('Origin', image)
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 高斯滤波
    gray = cv.GaussianBlur(gray, (9, 9), sigmaX=2, sigmaY=2)

    # 设置参数
    dp = 2                                  # 离散化累加器分辨率与图像分辨率的反比
    min_dist = 20                           # 两个圆心之间的最小距离
    param1 = 100                            # Canny边缘检测的较大阈值
    param2 = 100                            # 累加器阈值
    min_radius = 20                         # 圆形半径的最小值
    max_radius = 100                        # 圆形半径的最大值

    # 检测圆形
    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, dp, min_dist,
                              param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)
#circles存放维度为1*n*3的ndarray对象中，N表示检测出N个原型。对于每个结果，前两个数据分别是圆心的横、纵坐标，第3个数据是圆的半径
    # 绘制圆形
    draw_circle(image, circles)

    # 展示结果
    cv.imshow('Detect Circle Result', image)
    cv.waitKey(0)
    cv.destroyAllWindows()
values=[[[193.,183., 39.2],  [305., 119., 29.6],  [187.,253.  , 29.4],  [257.  ,235. ,  38.8],  [217. , 105.  , 40.8],  [323. , 259. ,  29.8],  [325.,  189.,   39. ],  [141. , 115.   ,34.6]]]
#####################################################################################################
import cv2 as cv
import sys

def draw_circle(img, values):
    for i in values[0, :,:]:#[0,:]表示取这个序列中的[0]号位置的所有数值，这里使用[0，：]也是可以的。
        cv.circle(img, (int(i[0]), int(i[1])), int(i[2]), (255, 0, 0), 2)
        cv.circle(img, (int(i[0]), int(i[1])), 2, (0, 255, 0), 3)

if __name__ == '__main__':
    # 读取图像circles.png
    image = cv.imread('./images/circles.png')
    if image is None:
        print('Failed to read circles.png.')
        sys.exit()
    cv.imshow('Origin', image)
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 高斯滤波
    gray = cv.GaussianBlur(gray, (9, 9), sigmaX=2, sigmaY=2)

    # 设置参数
    dp = 2                                  # 离散化累加器分辨率与图像分辨率的反比
    min_dist = 20                           # 两个圆心之间的最小距离
    param1 = 100                            # Canny边缘检测的较大阈值
    param2 = 100                            # 累加器阈值
    min_radius = 20                         # 圆形半径的最小值
    max_radius = 100                        # 圆形半径的最大值

    # 检测圆形
    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, dp, min_dist,
                              param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)
#circles存放维度为1*n*3的ndarray对象中，N表示检测出N个原型。对于每个结果，前两个数据分别是圆心的横、纵坐标，第3个数据是圆的半径
    # 绘制圆形
    draw_circle(image, circles)

    # 展示结果
    cv.imshow('Detect Circle Result', image)
    cv.waitKey(0)
    cv.destroyAllWindows()
###############圆的检测cv.HoghCircles()该函数会调用Camy边缘检测算法进行边缘检测’因此在检测圆形时不需要对灰度图像进行二值化’直接输入灰度图像即可°
######
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像circles.png
    image = cv.imread('./images/circles.png')
    if image is None:
        print('Failed to read circles.png.')
        sys.exit()
    cv.imshow('Origin', image)
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 高斯滤波
    gray = cv.GaussianBlur(gray, (9, 9), sigmaX=2, sigmaY=2)#为什么需要高斯滤波呢？

    # 二值化
    _, binary = cv.threshold(gray, 75, 180, cv.THRESH_BINARY)

    # 轮廓检测
    contours, hierarchy = cv.findContours(binary, mode=cv.RETR_TREE, method=cv.CHAIN_APPROX_SIMPLE)

    # 轮廓绘制
    image = cv.drawContours(image, contours, -1, (0, 0, 255), 2, 8)#-1表示画出所有的轮廓出来。

    # 输出轮廓结构关系
    print(hierarchy)

    # 展示结果
    cv.imshow('Find and Draw Contours', image)
    cv.waitKey(0)
    cv.destroyAllWindows()
#################################################轮廓检测cv.findContours(）的作用是找到轮廓，然后使用cv.drawContours()将轮廓绘制出来。这个参数中需要预处理，就是需要二值化来处理。我看到先使用了高斯滤波。最后得到的东西
###是一个矩阵。这个矩阵是一个表示各种轮廓位置关系的矩阵。
import cv2 as cv
import sys
import numpy as np

if __name__ == '__main__':
    # 用四个点表示三角形轮廓
    A = (0, 0)              # 顶点A
    B = (10, 0)             # 顶点B
    C = (10, 10)            # 顶点C
    D = (5, 5)              # 斜边中点D
    triangle = np.array((A, B, C, D))
    triangle_area = cv.contourArea(triangle)
    print('三角形面积为：{}'.format(triangle_area))

    # 读取图像circles.png
    image = cv.imread('./images/circles.png')
    if image is None:
        print('Failed to read circles.png.')
        sys.exit()

    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 高斯滤波
    gray = cv.GaussianBlur(gray, (9, 9), sigmaX=2, sigmaY=2)

    # 二值化
    binary = cv.threshold(gray, 75, 180, cv.THRESH_BINARY)#注意这里的binary 除了这种写法还有就是_,binary

    # 轮廓检测
    contours, hierarchy = cv.findContours(binary[1], mode=cv.RETR_TREE, method=cv.CHAIN_APPROX_SIMPLE)#contours是描述轮廓的坐标

    # 输出轮廓面积
    for i in range(len(contours)):
        img_area = cv.contourArea(contours[i])#这里轮廓面积其实说的是像素点
        print('第{}个轮廓面积为：{}'.format(i, img_area))
########################################################################cv.contourArea()是指像素面积。单位就是像素点。
import cv2 as cv
import sys
import numpy as np


if __name__ == '__main__':
    # 读取图像stuff.jpg
    image = cv.imread('./images/stuff.jpg')
    if image is None:
        print('Failed to read stuff.jpg.')
        sys.exit()
    cv.imshow('Origin', image)

    # 提取图像边缘
    canny = cv.Canny(image, 80, 160, 3)
    cv.imshow('Canny Image', canny)

    # 膨胀运算
    kernel = cv.getStructuringElement(0, (3, 3))
    canny = cv.dilate(canny, kernel=kernel)

    # 轮廓检测及绘制
    contours, hierarchy = cv.findContours(canny, mode=0, method=2)

    # 寻找并绘制轮廓外接矩形
    img1 = image.copy()
    img2 = image.copy()
    for i in range(len(contours)):#这个循环的意思是将所有的轮廓都显示出来，都画出来。
        # 绘制轮廓的最大外接矩形
        max_rect = cv.boundingRect(contours[i])
        cv.rectangle(img1, max_rect, (0, 0, 255), 2, 8, 0)#使用CV。boundingRect()读出来的刚好是左上角横纵坐标，宽和高，所以都是直接用的
        # 绘制轮廓的最小外接矩形
        min_rect = cv.minAreaRect(contours[i])#最小外界矩形三部曲，step1 使用cv.minAreaRect()得到一个tuple组，中间包含矩阵，但是呢相对最大矩阵多了旋转角度这个选项
        points = cv.boxPoints(min_rect).astype(np.int64)#step2 使用cv.boxPoints()就是用来返回4个顶角信息的参数。
        img2 = cv.drawContours(img2, [points], -1, (0, 255, 0), 2, 8)#step3 使用cv.drawContours()画最小矩形。

    cv.imshow('Max Rect', img1)
    cv.imshow('Min Rect', img2)
    cv.waitKey(0)
    cv.destroyAllWindows()
############################################################这一个函数很重要，主要是使用矩形画外接最小矩形和最大矩形，在我的项目天馈采集中得到了很好的应用。
import cv2 as cv
import sys
import numpy as np


def judge_shape(val):
    if val == 3:
        return 'Triangle'
    elif val == 4:
        return 'Rectangle'
    else:
        return 'Ploygon-{}'.format(val)
if __name__ == '__main__':
    # 读取图像approx.png
    image = cv.imread('./images/approx.png')
    if image is None:
        print('Failed to read approx.png.')
        sys.exit()

    # 提取图像边缘
    canny = cv.Canny(image, 80, 160, 3)

    # 膨胀运算
    kernel = cv.getStructuringElement(0, (3, 3))
    canny = cv.dilate(canny, kernel=kernel)

    # 轮廓检测及绘制
    contours, hierarchy = cv.findContours(canny, mode=0, method=2)

    for i in range(len(contours)):
        # 多边形拟合
        approx = cv.approxPolyDP(contours[i], 4, closed=True)
        print(f'sum的值是{sum(approx)}')
        print(f'approx的值是{approx}')
        print(f'approx的长度为{len(approx)}')#这里最
        # 多边形绘制
        image = cv.drawContours(image, [approx], -1, (0, 255, 0), 2, 8)#这个cv.drawContours（）用途真的是超级广泛
        # 在图中输出多边形形状
        # 计算并绘制多边形形状中心
        center = np.int0((sum(approx)[0] / len(approx)))#numpy.int0方法是将输入数组中的元素舍入为最接近的整数，然后强制转换为int类型。
        # 如果输入数组的类型为float，int0方法将其转换为等效的int类型，
        # 而不是执行四舍五入。对于其他输入类型，int0将其转换为等效的int类型。
        #arr = np.array([1.5, 2.4, 3.8])
       #print(np.int0(arr)) # 输出: [1 2 3]
        center = (center[0], center[1])
        cv.circle(image, center, 3, (0, 0, 255), -1)
        # 判断并绘制形状信息
        cv.putText(image, text=judge_shape(approx.shape[0]), org=center, fontFace=1, fontScale=1, color=(0, 0, 255))
    cv.imshow('ApproxPolyDP', image)
    cv.waitKey(0)
    cv.destroyAllWindows()
##################################cv.approxPolyDP()最大的意义我觉得是使用sum(aprox)/len来定位这些多边形的中心位置。 还有就是这里使用了膨胀操作，膨胀具有加粗的效果。有没有这个操作对最终的结果影响比较大。
import cv2 as cv
import sys
if __name__ == '__main__':
    # 读取图像approx.png
    image = cv.imread('./images/approx.png')
    if image is None:
        print('Failed to read approx.png.')
        sys.exit()

    # 提取图像边缘
    canny = cv.Canny(image, 80, 160, 3)

    # 膨胀运算
    kernel = cv.getStructuringElement(0, (3, 3))
    canny = cv.dilate(canny, kernel=kernel)

    # 轮廓检测及绘制
    contours, hierarchy = cv.findContours(canny, mode=0, method=2)

    # 创建图像中的一个点A
    point = (300, 100)

    # 判断点A距离各个轮廓的距离
    for i in range(len(contours)):
        dis = cv.pointPolygonTest(contours[i], point, measureDist=True)#若第3个参数
        # 是False表示输出结果不具有方问性只判断像素与轮廓之间的位置关系如果像素在轮廓的内部返回值为1;如果像素在轮廓的边缘上返回
        # 值为0;如果像素在轮廓的外部返回值为-1
        if dis > 0:
            pos = '内部'
        elif dis == 0:
            pos = '边缘上'
        else:
            pos = '外部'
        print('像素点A（300, 100）距离第{}个轮廓的距离为：{}，'
              '其位置位于轮廓{}'.format(i, round(dis, 2), pos))
#######################################################################点到轮廓的距离对于计算轮廓在图像中的位置、两个轮廓之间的距离以及确定图像上某点
是否在轮廓内部具有重要的作用。使用cv.cv.pointPolygonTest()函数。
import cv2 as cv
import sys
if __name__ == '__main__':
    # 读取图像hand.png
    image = cv.imread('./images/hand.png')
    if image is None:
        print('Failed to read hand.png.')
        sys.exit()

    # 灰度化
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 二值化
    _, binary = cv.threshold(gray, 105, 255, cv.THRESH_BINARY)#二值化只能对灰度图像才能进行

    # 对图像进行开运算
    kernel = cv.getStructuringElement(cv.MORPH_RECT, (9, 9), (-1, -1))
    binary = cv.morphologyEx(binary, cv.MORPH_OPEN, kernel)#cv.MORPH_OPEN开运算，开运算是先腐蚀后膨胀，去除杂质不伤图像质量。
    cv.imshow('Open', binary)

    # 轮廓检测
    contours, hierarchy = cv.findContours(binary, mode=cv.RETR_TREE, method=cv.CHAIN_APPROX_SIMPLE)

    # 计算并绘制凸包
    for i in contours:
        # 计算
        hull = cv.convexHull(i)#hull是顶包的顶点。
        # 绘制边缘
        image = cv.drawContours(image, [hull], -1, (0, 0, 255), 2, 8)
        # 绘制顶点
        for j in hull:
            cv.circle(image, (j[0][0], j[0][1]), 4, (255, 0, 0), 2, 8, 0)#其实不打顶点也可以。

    # 展示结果
    cv.imshow('ConvexHull', image)
    cv.waitKey(0)
    cv.destroyAllWindows()
################################cv.convexHull()针对复杂的图像求得顶包的坐标。这里是手的识别。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像approx.png
    image = cv.imread('./images/approx.png')
    if image is None:
        print('Failed to read approx.png.')
        sys.exit()

    # 灰度化
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 二值化
    _, binary = cv.threshold(gray, 105, 255, cv.THRESH_BINARY)

    # 对图像进行开运算
    kernel = cv.getStructuringElement(cv.MORPH_RECT, (9, 9), (-1, -1))
    binary = cv.morphologyEx(binary, cv.MORPH_OPEN, kernel)

    # 轮廓检测
    contours, hierarchy = cv.findContours(binary, mode=cv.RETR_TREE, method=cv.CHAIN_APPROX_SIMPLE)

    # 计算图像矩
    for i in contours:
        M = cv.moments(i)
        print('Spatial moments:')#空间矩
        print('m00: {}, m10: {}, m01: {}, m20: {}, m11: {}, m02: {}, m30: {}, m21: {}, m12: {}, m03: {}'
              .format(M['m00'], M['m10'], M['m01'], M['m20'], M['m11'], M['m02'], M['m30'], M['m21'], M['m12'], M['m03']))
        print('Central moments:')#中心距
        print('mu20: {}, mu11: {}, mu02: {}, mu30: {}, mu21: {}, mu12: {}, mu03: {}'
              .format(M['mu20'], M['mu11'], M['mu02'], M['mu30'], M['mu21'], M['mu12'], M['mu03']))
        print('Central normalized moments:')#中心矩归一化
        print('nu20: {}, nu11: {}, nu02: {}, nu30: {}, nu21: {}, nu12: {}, nu03: {}'
              .format(M['nu20'], M['nu11'], M['nu02'], M['nu30'], M['nu21'], M['nu12'], M['nu03']))
#注意：x代表的是像素的列号，而不是行号；y代表的是像素的行号，而不是列号。这一点可以在下面的示例代码的运行结果中看出。这也是为什么上面m的下标不是“ij”而是“ji”的原因。
#此时m 00称为叫图像的零阶空间矩，从这个计算式我们可以看出，图像的零阶空间矩实际上就是所有像素值的累加，零阶矩的值与像素的位置无关。
#只能看出来矩是矩类似于力矩概念。而且矩是用轮廓的基础上取出来的。
#注意下质心的定义 分母m00表示的是所有像素值累加，一阶分别表示x和y乘以对应的值。所以质心的概念可以推测得出。
#########################################################################################################
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像approx.png
    image = cv.imread('./images/approx.png')
    if image is None:
        print('Failed to read approx.png.')
        sys.exit()

    # 灰度化
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 二值化
    _, binary = cv.threshold(gray, 105, 255, cv.THRESH_BINARY)

    # 对图像进行开运算
    kernel = cv.getStructuringElement(cv.MORPH_RECT, (9, 9), (-1, -1))
    binary = cv.morphologyEx(binary, cv.MORPH_OPEN, kernel)

    # 轮廓检测
    contours, hierarchy = cv.findContours(binary, mode=cv.RETR_TREE, method=cv.CHAIN_APPROX_SIMPLE)

    # 计算图像矩
    for i in contours:
        M = cv.moments(i)
        # Hu距计算
        hu = cv.HuMoments(M)
        print(hu)
        #Hu矩 是由二阶和三阶中心矩得到的7个不变矩、Hu具有更加广泛用途
######################################################################################
import cv2 as cv
import sys
if __name__ == '__main__':
    # 读取图像ABC.png
    image1 = cv.imread('./images/ABC.png')
    if image1 is None:
        print('Failed to read ABC.png.')
        sys.exit()

    image2 = cv.imread('./images/B.png')
    if image2 is None:
        print('Failed to read B.png.')
        sys.exit()
    cv.imshow('B', image2)

    # 灰度化
    gray1 = cv.cvtColor(image1, cv.COLOR_BGR2GRAY)
    gray2 = cv.cvtColor(image2, cv.COLOR_BGR2GRAY)

    # 二值化
    _, binary1 = cv.threshold(gray1, 0, 255, cv.THRESH_BINARY)
    _, binary2 = cv.threshold(gray2, 0, 255, cv.THRESH_BINARY)

    # 轮廓检测
    contours1, _ = cv.findContours(binary1, mode=cv.RETR_TREE, method=cv.CHAIN_APPROX_SIMPLE)
    contours2, _ = cv.findContours(binary2, mode=cv.RETR_TREE, method=cv.CHAIN_APPROX_SIMPLE)

    # Hu距计算
    hu = cv.HuMoments(cv.moments(contours2[0]))#这是模板的轮廓

    # 轮廓匹配
    for i in range(len(contours1)):
        hu1 = cv.HuMoments(cv.moments(contours1[i]))
        dist = cv.matchShapes(hu1, hu, cv.CONTOURS_MATCH_I1, 0)#cv.matchShapes()
        print(dist)
        if dist < 1:
            cv.drawContours(image1, contours1, i, (0, 0, 255), 3, 8)#最终的结果由两个dist小于1，这个取值越小表示越接近。

    # 展示结果
    cv.imshow('Match Result', image1)
    cv.waitKey(0)
    cv.destroyAllWindows()
#############################################################使用了humoment来实现模板匹配的新方法。
import cv2 as cv
import numpy as np


if __name__ == '__main__':
    # 生成空白图像
    image = np.zeros((500, 500))

    # 生成随机点
    points = np.random.randint(150, 270, [100, 2]).astype('float32')

    # 在图像上绘制随机点
    for pt in points:
        cv.circle(image, (int(pt[0]), int(pt[1])), 1, (255, 255, 255), -1)
    image1 = image.copy()

    # 寻找包围点集的三角形
    _, triangle = cv.minEnclosingTriangle(np.array([points]))
    # 寻找包围点集的圆形
    center, radius = cv.minEnclosingCircle(points)

    # 绘制三角形（为便于读者理解，此处写出了triangle的详细拆分及绘制方式）

    a = triangle[0][0]
    b = triangle[1][0]
    c = triangle[2][0]
    cv.line(image, (int(a[0]), int(a[1])), (int(b[0]), int(b[1])), (255, 255, 255), 1, 16)
    cv.line(image, (int(a[0]), int(a[1])), (int(c[0]), int(c[1])), (255, 255, 255), 1, 16)
    cv.line(image, (int(b[0]), int(b[1])), (int(c[0]), int(c[1])), (255, 255, 255), 1, 16)

    # 绘制圆形
    center = np.int0(center)##numpy.int0方法是将输入数组中的元素舍入为最接近的整数，然后强制转换为int类型。因此
    cv.circle(image1, (center[0], center[1]), int(radius), (255, 255, 255), 1, cv.LINE_AA)

    # 展示结果
    cv.imshow('Triangle', image)
    cv.imshow('Circle', image1)
    cv.waitKey(0)
    cv.destroyAllWindows()
#######################################################################################使用triangle和circle时均需要将输入的坐标数据转成int形式的，不然报错。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像qrcode.png
    img = cv.imread('./images/qrcode.png', cv.IMREAD_GRAYSCALE)
    if img is None:
        print('Failed to read qrcode.png.')
        sys.exit()

    # 二维码检测和识别
    qr_detect = cv.QRCodeDetector()
    # 对二维码进行检测
    res, points = qr_detect.detect(img)#points是指二维码的4个顶点坐标，res包含bool类型的数据，图像是否有二维码
    if res:
        print('二维码顶点坐标为：\n{}'.format(points))

        # 对二维码进行解码
        ret, straight_qrcode = qr_detect.decode(img, points)#straight_qrcode经过校正和二值化的二维码
        print('二维码中信息为：\n{}'.format(ret))
        cv.namedWindow('Straight QRcode', cv.WINDOW_NORMAL)
        cv.imshow('Straight QRcode', straight_qrcode)

    # 定位并解码二维码
    ret1, points1, straight_qrcode1 = qr_detect.detectAndDecode(img)
    # 结果和上述相同，此处不再进行展示
    cv.waitKey(0)
    cv.destroyAllWindows()
#######################################
#####
#####CAPTER 8
#####
#######################################使用opencv读图像读二维码的过程。
import cv2 as cv
import numpy as np
import sys
np.set_printoptions(precision=3, suppress=True)#np.set_printoptions()用于控制Python中小数的显示精度。


if __name__ == '__main__':
    # 对矩阵进行处理
    a = np.array([[1, 2, 3],
                  [2, 3, 4],
                  [3, 4, 5]], dtype='float32')
    b = cv.dft(a, flags=cv.DFT_COMPLEX_OUTPUT)#DFT_COMPLEX_OUTPUT表示对一维或二实数数组进行正变换，结果是相同尺寸的具有复数共轭对称的复数矩阵。
    c = cv.dft(b, flags=cv.DFT_INVERSE | cv.DFT_SCALE | cv.DFT_REAL_OUTPUT)#INVERSE逆变换，DFT_SCALE缩放，FT_REAL_OUTPUT如果输入为复数，输出为实数。
    d = cv.idft(b, flags=cv.DFT_SCALE)#缩放标识，输出结果会除以输入元素的数目N，通常与dft_inverse
    print('正变换结果为：\n{}\n逆变换实数结果为：\n{}\n逆变换结果为：\n{}'.format(b, c, d))

    # 读取图像lena.png
    image = cv.imread('./images/lena.png')
    if image is None:
        print('Failed to read lena.png.')
        sys.exit()
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    gray = cv.resize(gray, (502, 502))

    image_height = gray.shape[0]
    image_width = gray.shape[1]
    # 计算合适的离散傅里叶变换尺寸
    height = cv.getOptimalDFTSize(image_height)#2、3、5公倍数才是最优的DFT SIZE。
    width = cv.getOptimalDFTSize(image_width)#2、3、5公倍数才是最优的DFT SIZE。

    # 扩展图像
    top = int((height - image_height) / 2)#原始图像上方扩展的像素行数
    bottom = int(height - image_height - top)#原始图像下方扩展的像素行数
    left = int((width - image_width) / 2)#原始图像左方扩展的像素行数
    right = int(width - image_width - left)#原始图像右方扩展的像素行数
    appropriate = cv.copyMakeBorder(gray, top=top, bottom=bottom, left=left, right=right, borderType=cv.BORDER_CONSTANT)
#cv.copyMakeBorder在不对图像进行缩放的前提下扩大图像的尺寸。
    # 计算幅值图像
    # 构建离散傅里叶变换输入量
    flo = np.zeros(appropriate.shape, dtype='float32')
    com = np.dstack([appropriate.astype('float32'), flo])#将给定数组拼接形成的3维以上的数组
    #按深度顺序堆叠arrays。当数组为2维数组(M, N)或1维数组(N, )时，首先分别将其维度改变为(M, N, 1)、(1, N, 1)，然后沿着第三根轴(r / g / b通道)进行拼接。
    # a = np.array([[1], [2], [3]])
    # b = np.array([[2], [3], [4]])
    # np.dstack((a, b))#
    # 结果是这个，纵向排列的。
    # [[[1, 2]],
    # [[2, 3]],
    # [[3, 4]]]
b = np.array([[2],[3],[4]])
np.dstack((a,b))

    # 进行离散傅里叶变换
    result = cv.dft(com, cv.DFT_COMPLEX_OUTPUT)
    # 将变换结果转为幅值
    magnitude_res = cv.magnitude(result[:, :, 0], result[:, :, 1])
    # 进行对数缩放
    magnitude_log = np.log(magnitude_res)#np.log()是以e为底的函数。
    # 将尺寸对应至原图像
    magnitude_res = magnitude_log[top:image_height, left:image_width]
    # 将结果进行归一化
    magnitude_norm = cv.normalize(magnitude_res, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)
    # 将幅值中心化处理
    magnitude_center = np.fft.fftshift(magnitude_norm)#将zero-frequency 分量移动到频谱的中心。

    # 展示结果
    cv.imshow('Origin', gray)
    cv.imshow('Border Result', appropriate)
    cv.imshow('Magnitude', magnitude_norm)
    cv.imshow('Magnitude (Center)', magnitude_center)
    cv.waitKey(0)
    cv.destroyAllWindows()
#####################################傅里叶变换的开局
import cv2 as cv
import numpy as np
import sys
if __name__ == '__main__':
    # 读取图像lena.png
    image = cv.imread('./images/lena.png')
    if image is None:
        print('Failed to read lena.png.')
        sys.exit()
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    gray_float = gray.astype('float32')#强制转换成了float32格式
    h, w = image.shape[:-1]#写成shape[:2]也是可以的

    # 构建卷积核
    kernel_w = 5
    kernel_h = 5
    kernel = np.ones((kernel_w, kernel_h), dtype='float32')

    # 计算最优离散傅里叶变换尺寸
    width = cv.getOptimalDFTSize(w + kernel_w - 1)#感觉这里非常像傅里叶变换的x+y-1模式
    height = cv.getOptimalDFTSize(h + kernel_h - 1)

    # 改变输入图像尺寸
    img_tmp = cv.copyMakeBorder(gray_float, 0, height - h, 0, width - w, cv.BORDER_CONSTANT)
    ##cv.copyMakeBorder在不对图像进行缩放的前提下扩大图像的尺寸。
    # 改变滤波器尺寸
    kernel_tmp = cv.copyMakeBorder(kernel, 0, height - kernel_h, 0, width - kernel_w, cv.BORDER_CONSTANT)

    # 分别对卷积核和图像进行傅里叶变换
    gray_dft = cv.dft(img_tmp, flags=0, nonzeroRows=w)
    kernel_dft = cv.dft(kernel_tmp, flags=0, nonzeroRows=kernel_w)

    # 多个傅里叶变换结果相乘
    result_mul = cv.mulSpectrums(gray_dft, kernel_dft, cv.DFT_COMPLEX_OUTPUT)

    # 对相乘结果逆变换
    result_idft = cv.idft(result_mul, flags=cv.DFT_SCALE, nonzeroRows=width)

    # 对逆变换结果归一化
    result_norm = cv.normalize(result_idft, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)
    result = result_norm[0: h, 0: w]
    # 展示结果
    cv.imshow('Origin', gray)
    cv.imshow('Result', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
########################################这个最主要讲的是使用cv.cv.mulSpectrums（）两个卷积相乘，我怎么感觉不太实用，乘完后图像更加模糊。
import cv2 as cv
import numpy as np
import sys
np.set_printoptions(suppress=True)


if __name__ == '__main__':
    # 对矩阵进行处理
    a = np.array([[1, 2, 3, 4, 5],
                  [2, 3, 4, 5, 6],
                  [3, 4, 5, 6, 7],
                  [4, 5, 6, 7, 8],
                  [5, 6, 7, 8, 9]], dtype='float32')
    b = cv.dct(a)
    c = cv.idct(b)
    print('原始数据为：\n{}\nDCT变换后数据为：\n{}\nDCT变换后逆变换结果为：\n{}'.format(a, b, np.int0(c)))#经过dct和idct变换后，

    # 对图像进行处理
    # 读取图像lena.png
    image = cv.imread('./images/lena.png')
    if image is None:
        print('Failed to read lena.png.')
        sys.exit()
    cv.imshow('Origin', image)

    image_height, image_width = image.shape[:-1]
    # 计算合适的离散傅里叶变换尺寸
    height = 2 * cv.getOptimalDFTSize(int((image_height + 1) / 2))#目前cv.dct0函数只支持列数（或元素个数）偶数的矩阵（或向量），注意在使用该函数处理数据时需要将数据填充到指定的尺寸.
    # 在实际使用中最佳｛尺寸可以通过2cv.getOptimalDFTSize（（N＋1）/2）计算
    width = 2 * cv.getOptimalDFTSize(int((image_width + 1) / 2))#

    # 扩展图像
    top = 0
    bottom = int(height - image_height - top)#只扩底部，顶部不变
    left = 0
    right = int(width - image_width - left)#只扩右边，左边不变
    appropriate = cv.copyMakeBorder(image, top=top, bottom=bottom, left=left, right=right, borderType=cv.BORDER_CONSTANT)

    # 三个通道需要分别进行DCT变换，cv.dct()函数只能变换单通道的矩阵，因此需要怼3个通道进行离散余弦变换。
    one, two, three = cv.split(appropriate)#b,g,r =cv.split()
    one_DCT = cv.dct(one.astype('float32'))
    two_DCT = cv.dct(two.astype('float32'))
    three_DCT = cv.dct(three.astype('float32'))

    # 进行通道合并
    result = cv.merge([one_DCT, two_DCT, three_DCT])

    # 保存结果
    cv.imwrite('./results/Dct.png', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
    #离散余弦变换主要用在信号和图像的有损压缩中。离散余弦变换具有“能量集中”的特性,信号经过变换后能量主要集中在结果的低频部分。在结果还可以看到经过余弦变换，然后逆变换，矩阵的值会改变。
#########################################################################################
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 读取图像lena.png
    image = cv.imread('./images/lena.png')
    if image is None:
        print('Failed to read lena.png.')
        sys.exit()
    h, w = image.shape[:-1]

    # 设置操作标志
    connectivity = 4                # 连通邻域方式
    maskVal = 255                   # 掩码图像的数值,表示掩模矩阵中被填充像素的值
    flags = connectivity | maskVal<<8 | cv.FLOODFILL_FIXED_RANGE    # 漫水填充操作方式标志
#cv.FLOODFILL_FIXED_RANGE 仅考虑当前像素值与初始种子点像素之间的差值，否则考虑新种子点像素与当前像素值之间的差异，即范围是否浮动的标志。
    # 设置与选中像素点的差值
    loDiff = (13, 13, 13)#当邻域中某像素值与种子像素值的差值大于该值时该像素被添加进种子点所在的区域。
    upDiff = (13, 13, 13)#当邻域中某像素值与种子像素值的差值小于该值时对应像素被添加进种子点所在的区域。

    # 声明掩模矩阵
    mask = np.zeros((h + 2, w + 2), dtype='uint8')#第2个参数用于标记漫水填充的区域非零像素点表示在原始图像中被填充的区域。掩模矩阵的列数和行数要比原始图像的宽和高大2，这里就是+2，并且需要在调用函数之前将该矩阵初始化。

    while True:
        # 随机选定图像中某一像素点
        x = np.random.randint(0, h)
        y = np.random.randint(0, w)
        pt = (x, y)

        # 彩色图像中填充像素值
        newVal = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))
        # 漫水填充
        area = cv.floodFill(image, mask, pt, newVal, loDiff, upDiff, flags)
        # 输出像素点和填充的像素数目
        print('像素点x：{}，y：{}，填充像素数目：{}'.format(x, y, area[0]))
        # 展示结果
        cv.imshow('flood fill', image)
        cv.imshow('mask', mask)
        k = cv.waitKey(0)
        if k == 27:#没有这个也行的。错了，这条是用来结束while循环的。
            break
    cv.destroyAllWindows()
###################################################
        for i in range(10):
            x = np.random.randint(0, h)
            y = np.random.randint(0, w)
            pt = (y, x)
#################将代码中的更换成这种就把图片所有位置都漫水了。这个程序可以让你理解一个为什么说漫水法是一种局部的图像分割法。
import cv2 as cv
import numpy as np
import sys


def generate_random_color():
    return np.random.randint(0, 256, 3)


def fill_color(img1, n, img2):
    h, w = img1.shape[:-1]
    res = np.zeros((h, w, 3), img1.dtype)
    # 生成随机颜色
    random_color = {}
    for c in range(1, n+1):
        random_color[c] = generate_random_color()
    # 填色
    for i in range(h):
        for j in range(w):
            item = img2[i][j]
            if item == -1:#标记图像中所有未被标记的像素值都为0。在函数输出时两个区域之间的分割线用-1表示。

                res[i, j, :] = (255, 255, 255)#是说rgb图像中的[i, j, 0],[i, j, 1],[i, j, 2]都这样赋值
            elif item == 0:#标记图像中所有未被标记的像素值都为0。在函数输出时两个区域之间的分割线用-1表示。
                res[i, j, :] = (0, 0, 0)
            else:
                res[i, j, :] = random_color[item]
    return res


if __name__ == '__main__':
    # 读取图像HoughLines.jpg
    image = cv.imread('./images/HoughLines.jpg')
    if image is None:
        print('Failed to read HoughLines.jpg.')
        sys.exit()
    cv.imshow('Origin', image)
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 高斯模糊便于减少边缘数目
    # gray = cv.GaussianBlur(gray, (5, 5), 10, sigmaY=20)

    # 提取图像边缘并进行闭运算
    mask = cv.Canny(gray, 150, 300)
    k = cv.getStructuringElement(0, (3, 3))
    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, k)
    cv.imshow('mask', mask)

    # 计算连通域数目
    contours, hierarchy = cv.findContours(mask, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)

    # 绘制轮廓，用于输入至分水岭算法
    mask_water = np.zeros(mask.shape, dtype='int32')
    for i in range(len(contours)):
        cv.drawContours(mask_water, contours, i, (i + 1), -1, 8, hierarchy)# 看到这里的hierarchy了吗？如果去掉也可以。
        #还有个信息是i, (i + 1),是什么呢？这个里面的颜色呢？
    # 分水岭算法操作
    result = cv.watershed(image, mask_water)
    # 为不同的分割区域绘制颜色
    result = fill_color(image, len(contours), mask_water)

    # 展示结果
    cv.imshow('Result', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
##################################################这里是使用分水岭算法来分割图像，是基于整个图像来做的。等有时间试试为什么不用在我们的天馈识别中。
##的例程使用图像边缘作为标记图像这具有一定的被动性，并且会产生众多较小的区域。在实际使用时通过人为标记的方式可能会得到更好的结果。
import cv2 as cv
import numpy as np
import sys
if __name__ == '__main__':
    # 读取图像lena.png
    image = cv.imread('./images/lena.png')
    if image is None:
        print('Failed to read lena.png.')
        sys.exit()
    h, w = image.shape[:-1]
    # 备份图像，防止绘制矩形框对结果产生影响
    imgRect = image.copy()
    imgRect = cv.rectangle(imgRect, (80, 30), (420, 420), (255, 255, 255), 3)
    cv.imshow('Select Area', imgRect)

    # 进行分割
    bgdmod = np.zeros((1, 65), dtype='float64')
    #print(bgdmod)
    fgdmod = np.zeros((1, 65), dtype='float64')
    mask = np.zeros(image.shape[:-1], dtype='uint8')
    mask, _, _ = cv.grabCut(image, mask, rect=(80, 30, 420, 420), bgdModel=bgdmod, fgdModel=fgdmod,
               iterCount=5, mode=cv.GC_INIT_WITH_RECT)#_,_分别表示bgdModel背景模型的临时数组，fgdMode1前景模型的临时数组

    # 将分割出的前景绘制出来
    for i in range(h):
        for j in range(w):
            n = mask[i, j]
            if n == 1 or n == 3:
                pass
            else:
                image[i, j, :] = 0#从这里看mask的值其实已经改变了，最后图像的分割结果也是通过分析掩模矩阵中每个像素值进行提取的。如果mask[i,j]为1，3则保持原值，如果否则直接变黑抹掉。

    # 展示结果
    cv.imshow('Result', image)
    cv.waitKey(0)
    cv.destroyAllWindows()
#################################################################cv.grabCut()方法，通过mask的变化来分割前景和背景。这个更像是一种抠图软件。
import cv2 as cv
import numpy as np
import sys
if __name__ == '__main__':
    # 读取图像keys.jpg
    image = cv.imread('./images/keys.jpg')
    if image is None:
        print('Failed to read keys.jpg.')
        sys.exit()

    # 定义迭代算法终止条件
    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 0.1)
    # 进行分割
    result1 = cv.pyrMeanShiftFiltering(image, 20, 40, maxLevel=2, termcrit=criteria)
    result2 = cv.pyrMeanShiftFiltering(result1, 20, 40, maxLevel=2, termcrit=criteria)

    # 对图像进行Canny边缘提取
    img_canny = cv.Canny(image, 150, 300)
    result1_canny = cv.Canny(result1, 150, 300)
    result2_canny = cv.Canny(result2, 150, 300)

    # 展示结果
    cv.imshow('Origin', image)
    cv.imshow('Origin Canny', img_canny)
    cv.imshow('Result1', result1)
    cv.imshow('Result1 Canny', result1_canny)
    cv.imshow('Result2', result2)
    cv.imshow('Result2 Canny', result2_canny)
    cv.waitKey(0)
    cv.destroyAllWindows()
#############################################################这个使用了CV. cv.pyrMeanShiftFiltering()的方法。每迭代一次图像的细节会消失掉。
import cv2 as cv
import sys

if __name__ == '__main__':
    # 读取图像lena.png
    image1 = cv.imread('./images/inpaint1.png')
    image2 = cv.imread('./images/inpaint2.png')
    if image1 is None or image2 is None:
        print('Failed to read inpaint1.png or inpaint2.png.')
        sys.exit()
    cv.imshow('Origin1', image1)
    cv.imshow('Origin2', image2)

    # 生成Mask掩模
    _, mask1 = cv.threshold(image1, 245, 255, cv.THRESH_BINARY)
    _, mask2 = cv.threshold(image2, 254, 255, cv.THRESH_BINARY)

    print(mask1.shape)
    # 对Mask膨胀处理，增加其面积
    k = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))
    mask1 = cv.dilate(mask1, k)
    mask2 = cv.dilate(mask2, k)
    cv.imshow('Mask1', mask1)
    cv.imshow('Mask2', mask2)
    # 图像修复
    result1 = cv.inpaint(image1, mask1[:, :, -1], 5, cv.INPAINT_NS)#mask1[:, :, -1]同于mask1[:, :, 2]
    result2 = cv.inpaint(image2, mask2[:, :, -1], 5, cv.INPAINT_NS)

    # 展示结果
    cv.imshow('Result1', result1)
    cv.imshow('Result2', result2)
    cv.waitKey(0)
    cv.destroyAllWindows()
##########################使用CV.inpaint()函数修复。思考为什么这里的掩码其实就是干扰的那个东西呢？可否用来除去水印呢。图像修复技术就是根据图像中损坏区域边缘的像素值大小及像素间的结构关系估计出损坏区
域可能的像素排列,从而去除图像中受“污染”的区域。
import cv2 as cv
import numpy as np
import sys

if __name__ == '__main__':
    # 读取图像
    image = cv.imread('./images/lena.jpg')
    if image is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    # 转为灰度图像
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

    # 计算Harris系数
    harris = cv.cornerHarris(gray, 2, 3, 0.04, borderType=cv.BORDER_DEFAULT)

    # 对Harris进行归一化便于进行数值比较
    harris_nor = cv.normalize(harris, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)
    harris_nor = harris_nor.astype('uint8')

    # 寻找Harris角点
    kps = []
    for i in np.argwhere(harris_nor > 125):#与125阈值相互比较，大于就保存下来。
        kps.append(cv.KeyPoint(float(i[1]), float(i[0]), 1))#则合理的cv.KeyPoint()里面是float属性。

    # 绘制角点
    result = cv.drawKeypoints(image, kps, None)

    # 展示结果
    cv.imshow('R', harris_nor)
    cv.imshow('Harris KeyPoints', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
#出Hams角点主要集中在图像人物的头发和帽子区域，因为这两个区域中线段的交点较多。
########################################################################
