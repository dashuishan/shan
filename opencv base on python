import cv2 as cv
import sys
if __name__=='__main__':
    #读取图形并判断是否成功
    img=cv.imread('./images/flower.jpg')
    if img is None:
        print('Failed to read flower.jpg.')
    else:
        print('图像的形状：{}\n元素数据类型:{}\n图像通道数:{}\n像素总数:{}'.format(img.shape,img.dtype,img.ndim,img.size))

Process finished with exit code 0
    #图像的形状：(442, 442, 3)
    #元素数据类型:uint8
    #图像通道数:3
    #像素总数:586092
    ##foamat函数的用法括号及其里面的字符 (称作格式化字段) 将会被 format() 中的参数替换
    #print("我叫{},今年{}!".format("张三", 22))
    #我叫张三, 今年22!
    ################################################################################################
import cv2 as cv
import numpy as np
import datetime
import sys


if __name__ == '__main__':
    # 创建ndarray对象
    # 使用np.array()创建一个5*5，数据类型为float32的对象
    a = np.array([[1, 2, 3, 4, 5],
                  [6, 7, 8, 9, 10],
                  [11, 12, 13, 14, 15],
                  [16, 17, 18, 19, 20],
                  [21, 22, 23, 24, 25]], dtype='float32')
    # 使用np.ones()创建一个5*5，数据类型为uint8的全1对象
    b = np.ones((5, 5), dtype='uint8')
    # 使用np.zeros()创建一个5*5，数据类型为float32的全0对象
    c = np.zeros((5, 5), dtype='float32')
    print('创建对象（np.array）：\n{}'.format(a))
    print('创建对象（np.ones）：\n{}'.format(b))
    print('创建对象（np.zeros）：\n{}'.format(c))

    # ndarray对象切片和索引
    image = cv.imread('./images/flower.jpg')
    # 判断图片是否读取成功
    if image is None:
        print('Failed to read flower.jpg.')
        sys.exit()
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    #cvtColor()函数是OpenCV里的颜色空间转换函数，可以实现RGB颜色向HSV、HSI等颜色空间的转换，也可以转换为灰度图像。
    # 读取图像位于（45,45）位置的像素点
    print('位于（45,45）位置的像素点为：{}'.format(gray[45, 45]))
    # 裁剪部分图像（灰度图像和RGB图像）
    res_gray = gray[40:280, 60:340]
    res_color1 = image[40:280, 60:340, :]
    res_color2 = image[100:220, 80:220, :]
    # 通道分离
    b = image[:, :, 0]
    g = image[:, :, 1]
    r = image[:, :, 2]
    # 展示裁剪和分离通道结果
    cv.imshow('Result crop gray', res_gray)
    cv.imshow('Result crop color1', res_color1)
    cv.imshow('Result crop color2', res_color2)
    cv.imshow('Result split b', b)
    cv.imshow('Result split g', g)
    cv.imshow('Result split r', r)

    # 生成随机数
    # 生成一个5*5，取值范围在0-100的数组
    values1 = np.random.randint(0, 100, (5, 5), dtype='uint8')
    # 生成一个2*3，元素服从平均值为0、标准差为1正态分布的数组，np.random.randn()是以0为均值、以1为标准差的正态分布，记为N（0，1）。
    values2 = np.random.randn(2, 3)
    print('生成随机数（np.random.randint）：\n{}'.format(values1))
    print('生成随机数（np.random.randn）：\n{}'.format(values2))

    cv.waitKey(0)
    cv.destroyAllWindows()
#. waitKey()–是在一个给定的时间内(单位ms)等待用户按键触发; 如果用户没有按下键,则继续等待 (循环)。常见 : 设置 waitKey(0) , 则表示程序会无限制的等待用户的按键事件，按任意键继续
####################################################################################################################################################
import cv2 as cv
import numpy as np
import datetime
import sys
if __name__ == '__main__':
    image = cv.imread('./images/flower.jpg')
    # 判断图片是否读取成功
    if image is None:
        print('Failed to read flower.jpg.')
        exit()

    # 对比通道的分离
    # 使用opencv中的cv.split()函数
    begin1 = datetime.datetime.now()
    for i in range(100000):
        b1, g1, r1 = cv.split(image)
    end1 = datetime.datetime.now()
    print('通道分离(opencv)：{}s'.format((end1 - begin1).total_seconds()))
    # 使用numpy中的切片和索引
    begin2 = datetime.datetime.now()
    for i in range(100000):
        b2 = image[:, :, 0]
        g2 = image[:, :, 1]
        r2 = image[:, :, 2]
    end2 = datetime.datetime.now()
    print('通道分离(numpy)：{}s'.format((end2 - begin2).total_seconds()))

    # 对比BGR图像转为RGB图像
    # 使用opencv中cv.cvtColor()函数
    begin3 = datetime.datetime.now()
    for i in range(100000):
        image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)
    end3 = datetime.datetime.now()
    print('BGR转RGB(opencv)：{}s'.format((end3 - begin3).total_seconds()))
    # 使用numpy中的切片和索引
    begin4 = datetime.datetime.now()
    for i in range(100000):
        image_rgb = image[:, :, ::-1]
        #img[:,:,::-1]也就是我们任意不改变width维的方式，也不改变height维的方式，仅仅改变channel维的方式，并且是倒序排列，原本的bgr排列方式经过倒序就变成了rgb的通道排列方式。
        #img = img[:, :, ::-1].transpose(2, 0, 1)，transpose输入顺序NxCxHxW,我们将图片从HxWxC改为CxHxW的形式。
        #img[::-1, :, :]其实是对图片进行上下翻转， img[:,::-1,:]是对图像进行左右翻转
    end4 = datetime.datetime.now()
    print('BGR转RGB(numpy)：{}s'.format((end4 - begin4).total_seconds()))
#首先需要明白一点，我们通过cv2读图片时，数据读取的通道顺序是bgr，并且是height， width， channel的排列方式。
运行后结果为：
通道分离(opencv)：8.014632s
通道分离(numpy)：0.042004s
BGR转RGB(opencv)：2.087166s
BGR转RGB(numpy)：0.020182s
# 在python中经常会用到计算两个时间差，两个日期类型进行相减可以获取到时间差。经常会使用seconds来获取，其实seconds获取的是仅仅是时间差的秒数，忽略微秒数，忽略天数。
# total_seconds()是获取两个时间之间的总差
# t1 = datetime.datetime.strptime("2017-9-06 10:30:00", "%Y-%m-%d %H:%M:%S")
# t2 = datetime.datetime.strptime("2017-9-08 12:30:00", "%Y-%m-%d %H:%M:%S")
# interval_time = (t2 - t1).seconds  # 输入的结果：7200
# total_interval_time = (t2 - t1).total_seconds() # 输出结果是: 180000.0
# print interval_time
# print total_interval_time
######################################################这里使用numpy和opecv两种方法去对比，对图片进行处理的效率问题。
import cv2 as cv
if __name__ == '__main__':
    video = cv.VideoCapture('./videos/road.mp4')
    # 判断是否成功创建视频流
    while video.isOpened():
        ret, frame = video.read()#ret变量表示是否成功从vidio中读出图像，读出则为true，没读出为false。也用来判断是否视频是否到了末尾。
        if ret is True:
            cv.imshow('Video', frame)
            # 设置视频播放速度
            # 读者可以尝试将该值做更改，并观看视频播放速度的变化
            cv.waitKey(int(1000 / video.get(cv.CAP_PROP_FPS)))
            #，当imshow之后不跟waitkey时，相当于没有给imshow提供时间展示图像，所以只有一个空窗口一闪而过。添加了waitkey后，哪怕仅仅是cv2.waitkey(1),我们也能截取到一帧的图像。所以cv2.imshow后边是必须要跟cv2.waitkey的。
            #imshow（）后面必接cv.waitkey()，以显示图像。必须必须接！！This function is the only method in HighGUI that can fetch and handle events,so it needs to be
            # 按下q退出
            if cv.waitKey(1) & 0xFF == ord('q'):
            #0xFF是一个十六进制数，转换为二进制是11111111。waitKey返回值的范围为（0-255），刚好也是8个二进制位。那么我们将 cv2.waitKey(1) & 0xFF计算一下（不知怎么计算的可以百度位与运算）发现结果仍然是waitKey的返回值，那为何要多次一举呢？直接 cv2.waitKey(1) == ord('q')不就好了吗。
            #实际上在linux上使用waitkey有时会出现waitkey返回值超过了（0-255）的范围的现象。通过cv2.waitKey(1) & 0xFF运算，当waitkey返回值正常时 cv2.waitKey(1) = cv2.waitKey(1000) & 0xFF,当返回值不正常时，cv2.waitKey(1000) & 0xFF的范围仍不超过（0-255），就避免了一些奇奇怪怪的BUG。
            #ord('q')的意思是返回q的ascii码，
                break
        else:
            break
    # 输出相关信息
    print('视频中图像的宽度为：{}'.format(video.get(cv.CAP_PROP_FRAME_WIDTH)))
    print('视频中图像的高度为：{}'.format(video.get(cv.CAP_PROP_FRAME_HEIGHT)))
    print('视频帧率为：{}'.format(video.get(cv.CAP_PROP_FPS)))
    print('视频总帧数为：{}'.format(video.get(cv.CAP_PROP_FRAME_COUNT)))
    #cv.VideoCapture提供了get(propID)函数来获取视频属性，如视频的像素大小、帧数和帧率。
    # 释放并关闭窗口
    video.release()
    cv.destroyAllWindows()
    ########################################################################################读取视频的方法。
import cv2 as cv
import sys
import numpy as np
import matplotlib.pyplot as plt
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/flower.jpg')
    if img is None:
        print('Failed to read flower.jpg.')
        sys.exit()
    else:
        # 添加alpha通道（cv.merge()函数将在第三章做具体讲解）
        zeros = np.ones(img.shape[:2], dtype=img.dtype) * 100
        #img.shape[:2] 取彩色图片的长、宽,如果img.shape[:3] 则取彩色图片的长、宽、通道
        print(zeros.shape)
        result = cv.merge([img, zeros])
        #print(result)结果为三维的数组
        print('原图的通道数为：{}'.format(img.shape[2]))
        print('处理后的通道数为：{}'.format(result.shape[2]))
        #关于img.shape[0]、[1]、[2],img.shape[0]：图像的垂直尺寸（高度）,img.shape[1]：图像的水平尺寸（宽度）,img.shape[2]：图像的通道数
        # 图像展示
        plt.imshow(result)
        plt.show()
        # 图像保存
        cv.imwrite('./results/flower_alpha.png', result)
      #######################################################图像的alpha通道，作用是调节图像的透明度。这里我用plt.imshow（）函数显示的，图像融合的时候需要乘以100,如果使用imshow就没有这个问题了额。
import cv2 as cv
if __name__ == '__main__':
    # 设置编/解码方式
    fourcc = cv.VideoWriter_fourcc(*'DIVX')
    #这种写法是表示使用MPEG-4进行编码

    #  采用摄像头获取图像
    video = cv.VideoCapture(0)
    # 第一种使用cv.VideoWriter()函数的原型（两种方法效果相同）
    # result = cv.VideoWriter()
    # result.open('./videos/Save_video.avi', fourcc, 20.0, (640, 480))
    # 第二种使用cv.VideoWriter()构造函数
    result = cv.VideoWriter('./videos/Save_video.avi', fourcc, 20.0, (640, 480))

    # 判断是否成功创建视频流
    while video.isOpened():
        ret, frame = video.read()
        if ret is True:
            # 将每一帧图像进行水平翻转
            frame = cv.flip(frame, 1)
            #想象一下原始的图像是一种左右倒置的图像，需要进行左右旋转才能被用户所观看

            # 将一帧一帧图像写入视频
            result.write(frame)
            cv.imshow('Video', frame)
            cv.waitKey(25)

            # 键盘按下q退出
            if cv.waitKey(1) & 0xFF == ord('q'):
                break
        else:
            break

    # 释放并关闭窗口
    video.release()
    result.release()
    cv.destroyAllWindows()
    #########################################################这是调用电脑的摄像头 进行图像拍摄并保存的代码实例。
import cv2 as cv
import numpy as np


if __name__ == '__main__':
    # 创建FileStorage对象file，用于写入数据
    # 读者可以尝试将文件后缀名改为.yml或.yaml
    # file = cv.FileStorage('./data/MyFile.yml', cv.FileStorage_WRITE)
    # file = cv.FileStorage('./data/MyFile.yaml', cv.FileStorage_WRITE)
    file = cv.FileStorage('./data/MyFile.xml', cv.FileStorage_WRITE)
    #除了保存图像外，长度较小的ndarray数组对象，字符串，数组等数据也需要保存，通常保存为xml或者YAML文件。

    # 写入数据
    file.write('name', '张三')
    file.write('age', 16)
    file.write('date', '2019-01-01')
    scores = np.array([[98, 99], [96, 97], [95, 98]])
    file.write('scores', scores)

    # 释放对象
    file.release()
    # 创建FileStorage对象file1，用于读取数据
    file1 = cv.FileStorage('./data/MyFile.xml', cv.FileStorage_READ)
    # 判断MyFile.xml文件是否成功打开
    if file1.isOpened():
        # 读取数据
        name1 = file1.getNode('name').string()
        age1 = file1.getNode('age').real()
        date1 = file1.getNode('date').string()
        scores1 = file1.getNode('scores').mat()
        #这里三种类型 string(),real(),mat()分别对应的字符串型，实数型和矩阵型，目前只有这三种类型的数值。
        # 展示读取结果
        print('姓名：{}'.format(name1))
        print('年龄：{}'.format(age1))
        print('记录日期：{}'.format(date1))
        print('成绩单：{}'.format(scores1))
    else:
        print('Can\'t open MyFile.xml.')
    # 释放对象
    file1.release()
###############################################使用CV保存三种类型的文件，并读取他们，现在的文件类型只有字符串 实数 和矩阵类型的了。读取和存储都采用的file.getNode('x').real()来进行读写的。
import cv2 as cv
import sys
import numpy as np


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    else:

        # 将图像进行颜色模型转换
        image = img.astype('float32')#img.astype可以对数据类型进行转换
        image *= 1.0 / 255
        #数据类型float32的图像的像素范围为0~1,在将图像类型为unit8的图像转换成数据类型为float32的图像时，需要先将图像像素除于255以缩放到0~1范围内。
        HSV = cv.cvtColor(image, cv.COLOR_BGR2HSV)
        YUV = cv.cvtColor(image, cv.COLOR_BGR2YUV)
        Lab = cv.cvtColor(image, cv.COLOR_BGR2Lab)
        GRAY = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

        # 展示结果
        cv.imshow('Origin Image', image)
        cv.imshow('HSV Image', HSV)
        cv.imshow('YUV Image', YUV)
        cv.imshow('Lab Image', Lab)
        # 由于计算出Lab结果会有负数值，不能通过cv.imshow()函数显示
        # 因此我们可以使用cv.imwrite()函数保存下来进行查看
        cv.imwrite('./results/Convert_color_Lab.jpg', Lab)
        cv.imshow('GRAY Image', GRAY)
        #这里适合用imshow来显示多个图像的时候，也是使用cv.waitKey()去做配合等待。
        # 关闭窗口
        cv.waitKey(0)
        cv.destroyAllWindows()
#####################################################这个是色彩空间的转换，但是我依然没有明白的问题是！、img.astype('float32')转换前为什么需要弄成float32的模式，后面要除以255就会出现错误提示。两种不同类别不能互相操作。
#################################################2是为什么lab类型因为是负值无法读取，保存了就可以读取了吗》imread()有这么鄙视负值吗？
# -*- coding:utf-8 -*-
import cv2 as cv
import sys
import numpy as np


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    # 通道分离
    b, g, r = cv.split(img)

    # 创建一个和图像尺寸相同的全0矩阵
    zeros = np.zeros(img.shape[:2], dtype='uint8')

    # 将通道数目相同的图像矩阵合并
    bg = cv.merge([b, g, zeros])
    gr = cv.merge([zeros, g, r])
    br = cv.merge([b, zeros, r])
    # 将通道数目不相同的图像矩阵合并
    bgr_6 = cv.merge([bg, r, zeros, zeros])

    # 展示结果
    cv.imshow('Blue', b)
    cv.imshow('Green', g)
    cv.imshow('Red', r)
    cv.imshow('Blue_Green', bg)
    cv.imshow('Green_Red', gr)
    cv.imshow('Blue_Red', br)

    # 关闭窗口
    cv.waitKey(0)
    cv.destroyAllWindows()#由于双通道矩阵不能通过 cvimshow0进行查看，因此3个通道的矩阵,回忆一下是使用numpy的方法如何实现通道的分离。
b2 = image[:, :, 0] g2 = image[:, :, 1],r2 = image[:, :, 2]
############################################################################################################
import cv2 as cv
import numpy as np


if __name__ == '__main__':
    # 新建矩阵array
    array = np.array([1, 2, 3, 4, 5, 10, 6, 7, 8, 9, 10, 0])

    # 将array调整为3*4的单通道图像
    img1 = array.reshape(3, 4)
    print(img1)
    minval_1, maxval_1, minloc_1, maxloc_1 = cv.minMaxLoc(img1)
    print('图像img1中最小值为：{}, 其位置为：{}' .format(minval_1, minloc_1))
    print('图像img1中最大值为：{}, 其位置为：{}' .format(maxval_1, maxloc_1))

    # 先将array调整为为3*2*2的多通道图像
    img2 = array.reshape((3, 2, 2))
   #也可以这么来写   img2 = np.reshape(img1,(3, 2, 2))
    # 再利用-1的方法调整尺寸

    print(img2)
    img2_re = img2.reshape((1, -1))#将变化后的矩阵又变成了一维。这里用单括号也是可以的。主要是-1的应用是个什么鬼呢？（已解决）
    #使用了reshape（-1，1）之后，数据集变成了一列。reshape(1,-1)呢？也就是直接变成了一行了。这个-1在这里要怎么理解呢？
    #跟进numpy库官网的介绍，这里的-1被理解为unspecified value，意思是未指定为给定的。如果我只需要特定的行数，列数多少无所谓，只需要指定行数，那么列数直接用-1代替就行了，
    # 计算机帮我们算赢有多少列，反之亦然。
    #所以-1在这里应该可以理解为一个正整数通配符，它代替任何整数。
print(img2_re)
    minval_2, maxval_2, minloc_2, maxloc_2 = cv.minMaxLoc(img2_re)
    print('图像img2中最小值为：{}, 其位置为：{}'.format(minval_2, minloc_2))
    print('图像img2中最大值为：{}, 其位置为：{}'.format(maxval_2, maxloc_2))
##############################################################################################################
import cv2 as cv
import numpy as np
if __name__ == '__main__':
    # 新建矩阵array
    array = np.array([1, 2, 3, 4, 5, 10, 6, 7, 8, 9, 10, 0])
    # 将array调整为3*4的单通道图像img1
    img1 = array.reshape((3, 4))
    # 将array调整为3*2*2的多通道图像img2
    img2 = array.reshape((3, 2, 2))

    # 分别计算图像img1和图像img2的平均值和标准差
    mean_img1 = cv.mean(img1)
    mean_img2 = cv.mean(img2)

    mean_std_dev_img1 = cv.meanStdDev(img1)
    mean_std_dev_img2 = cv.meanStdDev(img2)

    # 输出cv.mean()函数计算结果
    print('cv.mean()函数计算结果如下：')
    print('图像img1的均值为：{}'.format(mean_img1))
    print(f"img1的矩阵为{img1}")
    print('图像img2的均值为：{}\n第一个通道的均值为：{}\n第二个通道的均值为：{}'
          .format(mean_img2, mean_img2[0], mean_img2[1]))
    print(f"img2的矩阵为{img2}")
    print('*' * 30)
    # 输出cv.meanStdDev()函数计算结果
    print('cv.meanStdDev()函数计算结果如下：')
    print('图像img1的均值为：{}\n标准差为：{}'.format(mean_img1[0], float(mean_std_dev_img1[1])))
    print('图像img2的均值为：{}\n第一个通道的均值为：{}\n第二个通道的均值为：{}\n'
          '标准差为：{}\n第一个通道的标准差为：{}\n第二个通道的标准差为：{}\n'
          .format(mean_img2, mean_img2[0], mean_img2[1],
                  mean_std_dev_img2[1], float(mean_std_dev_img2[1][0]), float(mean_std_dev_img2[1][1])))
#############################################################################这里是计算图像的均值和标准差的结果。这里的图片矩阵为(3, 2, 2)，但是图片是两通道，所以显示通道1和通道2。通道1、2的计算方法如下所示
img2的矩阵为[[[ 1  2]
  [ 3  4]]
 [[ 5 10]
  [ 6  7]]
 [[ 8  9]
  [10  0]]]
通道1的均值为（1+3+5+6+8+9+10）/6=5.5,通道2的均值为（2+4+10+7+9+0）/6=5.3333333这就对通道做了 充分的认识了。
这段程序还需要注意的点是计算方差采用的是(mean_std_dev_img2[1][0]，这样是因为mean_std_dev_img[0]记录的是平均值。
############################################################################################################################
# -*- coding:utf-8 -*-
import cv2 as cv
import numpy as np


if __name__ == '__main__':
    # 新建矩阵a和b
    a = np.array([1, 2, 3.3, 4, 5, 9, 5, 7, 8.2, 9, 10, 2])
    b = np.array([1, 2.2, 3, 1, 3, 10, 6, 7, 8, 9.3, 10, 1])
    img1 = np.reshape(a, (3, 4))
    img2 = np.reshape(b, (3, 4))
    img3 = np.reshape(a, (2, 3, 2))
    img4 = np.reshape(b, (2, 3, 2))

    # 对两个单通道图像矩阵进行比较运算
    max12 = cv.max(img1, img2)
    min12 = cv.min(img1, img2)
    print(f"img1 是{img1}")
    print(f"img2 是{img2}")
    print(f"max12 是{max12}")
    print(f"min12 是{min12}")


    # 对两个多通道图像矩阵进行比较运算
    max34 = cv.max(img3, img4)
    min34 = cv.min(img3, img4)

    # 对两张彩色图像进行比较运算
    img5 = cv.imread('./images/lena.jpg')
    img6 = cv.imread('./images/noobcv.jpg')
    print(f"img5 是{img5}")
    print(f"img6 是{img6}")
    max56 = cv.max(img5, img6)
    min56 = cv.min(img5, img6)
    cv.imshow('conMax', max56)
    cv.imshow('conMin', min56)
    print(f"max56 是{max56}")
    # 对两张灰度图像进行比较运算
    img7 = cv.cvtColor(img5, cv.COLOR_BGR2GRAY)
    img8 = cv.cvtColor(img6, cv.COLOR_BGR2GRAY)
    max78 = cv.max(img7, img8)
    min78 = cv.min(img7, img8)
    cv.imshow('conMax_GRAY', max78)
    cv.imshow('conMin_GRAY', min78)

    # 与掩模进行比较运算
    # 生成一个低通300*300的掩模矩阵
    src = np.zeros((512, 512, 3), dtype='uint8')
    src[100:400:, 100:400:] = 255
    print(img5.shape)
    min_img5_src = cv.min(img5, src)
    cv.imshow('Min img5 src', min_img5_src)

    # 生成一个显示红色通道的低通掩模矩阵
    src1 = np.zeros((512, 512, 3), dtype='uint8')
    src1[:, :, 2] = 255#r = image[:, :, 2]就是红色通道取值255。
    min_img5_src1 = cv.min(img5, src1)
    cv.imshow('Min img5 src1', min_img5_src1)

    # 关闭窗口
    cv.waitKey(0)
    cv.destroyAllWindows()
##############################################################################这里一个很显然的问题是无论是CV.min() 还是CV.max()都是比较每个维度的值，举例说明img6 是[[[218 135  26]，img5 是[[[128 138 225]，max56 是[[[218 138 225]
############################然后需要做的是 仔细观察像素取最大的结果是什么样子的。有利于以后灵活开发工作。
import cv2 as cv
import numpy as np
if __name__ == '__main__':
    # 创建两个黑白图像
    img1 = np.zeros((200, 200), dtype='uint8')
    img2 = np.zeros((200, 200), dtype='uint8')
    img1[50:150, 50:150] = 255
    img2[100:200, 100:200] = 255
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    # 进行逻辑运算
    Not = cv.bitwise_not(img1)
    And = cv.bitwise_and(img1, img2)
    Or = cv.bitwise_or(img1, img2)
    Xor = cv.bitwise_xor(img1, img2)#异或如果两个位的值相同（同为 0 或同为 1），则结果位等于 0；否则结果位等于 1。
    img_Not = cv.bitwise_not(img)

    # 展示结果
    cv.imshow('img1', img1)
    cv.imshow('img2', img2)
    cv.imshow('Not', Not)
    cv.imshow('And', And)
    cv.imshow('Or', Or)
    cv.imshow('Xor', Xor)
    cv.imshow('Origin', img)
    cv.imshow('Img_Not', img_Not)
    cv.waitKey(0)
    cv.destroyAllWindows()
#################################################这是二值化图像的逻辑运算
import cv2 as cv
import numpy as np


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    # 彩色图像二值化
    _, img_B = cv.threshold(img, 125, 255, cv.THRESH_BINARY)
    _, img_B_V = cv.threshold(img, 125, 255, cv.THRESH_BINARY_INV)
    cv.imshow('img_B', img_B)
    cv.imshow('img_B_V', img_B_V)
    # 灰度图像二值化
    _, gray_B = cv.threshold(gray, 125, 255, cv.THRESH_BINARY)
    _, gray_B_V = cv.threshold(gray, 125, 255, cv.THRESH_BINARY_INV)
    cv.imshow('gray_B', gray_B)
    cv.imshow('gray_B_V', gray_B_V)
    # 灰度图像TOZERO变换，1、这个也是线性的保持灰度值，TOZERO是保持阈值以上的细节，TOZERO_INV是保持阈值以下的细节
    _, gray_T = cv.threshold(gray, 125, 255, cv.THRESH_TOZERO)
    _, gray_T_V = cv.threshold(gray, 125, 255, cv.THRESH_TOZERO_INV)
    cv.imshow('gray_T', gray_T)
    cv.imshow('gray_T_V', gray_T_V)
    # 1、灰度图像TRUNC变换，TRUNC（）中文意思是截断的意思。第三个值maxval=255是不起作用的。就是削顶的意思。2值得注意的是并非二值化，而是保留了以前的灰度，让他有更多的细节
    _, gray_TRUNC = cv.threshold(gray, 125, 255, cv.THRESH_TRUNC)
    cv.imshow('gray_TRUNC', gray_TRUNC)
    # 灰度图像大律法和三角形法二值化，这两种方法与前面的方法合用就可以对阈值进行更加合理的设置。因为毕竟所有的图片不可能全部了解。但是这种方法二值化还是存在问题的，
    #如在阴影区域的
    img1 = cv.imread('./images/threshold.png', cv.IMREAD_GRAYSCALE)
    _, img1_O = cv.threshold(img1, 100, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)
    _, img1_T = cv.threshold(img1, 125, 255, cv.THRESH_BINARY | cv.THRESH_TRIANGLE)
    cv.imshow('img1', img1)
    cv.imshow('img1_O', img1_O)
    cv.imshow('img1_T', img1_T)
    # 灰度图像自适应二值化，我觉得这种可能用的更加多一些。
    adaptive_mean = cv.adaptiveThreshold(img1, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 13, 0)
    adaptive_gauss = cv.adaptiveThreshold(img1, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 13, 0)
    cv.imshow('adaptive_mean', adaptive_mean)
    cv.imshow('adaptive_gauss', adaptive_gauss)
    cv.waitKey(0)
    cv.destroyAllWindows()
########################################################################################这是很重要的一环  将图像（包含彩色和灰度图像)二值化,在日常的应用中有很重要的位置。
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # LUT查找表第一层
    LUT_1 = np.zeros(256, dtype='uint8')
    LUT_1[101: 201] = 100
    LUT_1[201:] = 255
    # LUT查找表第二层
    LUT_2 = np.zeros(256, dtype='uint8')
    LUT_2[101: 151] = 100
    LUT_2[151: 201] = 150
    LUT_2[201:] = 255
    # LUT查找表第三层
    LUT_3 = np.zeros(256, dtype='uint8')
    LUT_3[0: 101] = 100
    LUT_3[101: 201] = 200
    LUT_3[201:] = 255

    # LUT三通道合并
    LUT = cv.merge((LUT_1, LUT_2, LUT_3))
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    out0 = cv.LUT(gray, LUT_1)#一维的映射表
    out1 = cv.LUT(img, LUT_1)
    out2 = cv.LUT(img, LUT)#三维的映射表

    # 展示结果
    cv.imshow('out0', out0)
    cv.imshow('out1', out1)
    cv.imshow('out2', out2)
    cv.waitKey(0)
    cv.destroyAllWindows()
##########################################################常用的cv.threshold（）只有一个阈值，如果需要多个阈值 我们就使用cv.LUT()的方式，目前来看这种方式不一定使用频繁。后面如果在使用直方图的均衡时有大作用。
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 矩阵的垂直和水平连接
    # 定义矩阵A和B
    A = np.array([[1, 7], [2, 8]])
    print(f"A的{A.shape}")

    B = np.array([[4, 10], [5, 11]])
    print(f"B的{B.shape}")
    # 垂直连接
    V_C = cv.vconcat((A, B))
    print(f"V_C的{V_C.shape}")
    # 水平连接
    H_C = cv.hconcat((A, B))
    print(f"H_C的{H_C.shape}")
    print('垂直连接结果：\n{}'.format(V_C))
    print('水平连接结果：\n{}'.format(H_C))

    # 图像的垂直和水平连接
    # 读取四张图像
    # 读取图像并判断是否读取成功
    img00 = cv.imread('./images/lena00.jpg')
    img01 = cv.imread('./images/lena01.jpg')
    img10 = cv.imread('./images/lena10.jpg')
    img11 = cv.imread('./images/lena11.jpg')
    if img00 is None or img01 is None or img10 is None or img11 is None:
        print('Failed to read images.')
        sys.exit()

    # 图像连接
    # 水平连接
    img0 = cv.hconcat((img00, img01))
    img1 = cv.hconcat((img10, img11))
    # 垂直连接
    img = cv.vconcat((img0, img1))
    # 显示结果
    cv.imshow('img00', img00)
    cv.imshow('img01', img01)
    cv.imshow('img10', img10)
    cv.imshow('img11', img11)
    cv.imshow('img0', img0)
    cv.imshow('img1', img1)
    cv.imshow('img', img)
    cv.waitKey(0)
    cv.destroyAllWindows()
################################################图像的横向和纵向连接很容易直观的看到，矩阵的形式则是更加说明这个连接的核心。我读取了他们的shape。
A的(2, 2)
B的(2, 2)
V_C的(4, 2)#横向连接
H_C的(2, 4)#纵向连接
##################################################################################
import cv2 as cv
import sys
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg', cv.IMREAD_GRAYSCALE)
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    # 将图像缩小
    small_img = cv.resize(img, (15, 15), fx=0, fy=0, interpolation=cv.INTER_AREA)
    print(f"small_img的尺寸为{small_img.shape}")
    #结果显示small_img的尺寸为(15, 15)
    # 最近邻插值
    big_img1 = cv.resize(small_img, (30, 30), fx=0, fy=0, interpolation=cv.INTER_NEAREST)
    print(f"big_img1的尺寸为{big_img1.shape}")
    #结果显示big_img1的尺寸为(30, 30)
    # 双线性插值
    big_img2 = cv.resize(small_img, (30, 30), fx=0, fy=0, interpolation=cv.INTER_LINEAR)
    # 双三次插值
    big_img3 = cv.resize(small_img, (30, 30), fx=0, fy=0, interpolation=cv.INTER_CUBIC)
    # 展示结果
    cv.imshow('img',img)
    cv.namedWindow('small', cv.WINDOW_NORMAL)#cv.namedWindow(winname[, flags]),创建一个窗口,WINDOW_NORMAL：窗口尺寸可变,如果用imshow()直接去读则生成的窗口是不能更改的。
    cv.imshow('small', small_img)
    cv.namedWindow('big_img1', cv.WINDOW_NORMAL)
    cv.imshow('big_img1', big_img1)
    cv.namedWindow('big_img2', cv.WINDOW_NORMAL)
    cv.imshow('big_img2', big_img2)
    cv.namedWindow('big_img3', cv.WINDOW_NORMAL)
    cv.imshow('big_img3', big_img3)
    cv.waitKey(0)
    cv.destroyAllWindows()
##############################################################################cv.resize()的用法。
import cv2 as cv
import sys
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    # 沿x轴对称
    img_x = cv.flip(img, 0)
    # 沿y轴对称
    img_y = cv.flip(img, 1)
    # 先x轴对称，再y轴对称
    img_xy = cv.flip(img, -1)
    # 展示结果
    cv.imshow('img', img)
    cv.imshow('img_x', img_x)
    cv.imshow('img_y', img_y)
    cv.imshow('img_xy', img_xy)
    cv.waitKey(0)
    cv.destroyAllWindows()
########################################################图片反转的用法。
mport cv2 as cv
import numpy as np
import sys
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    # 设置图像旋转角度、尺寸、旋转中心参数
    angle = 30
    h, w = img.shape[:-1]
    size = (w, h)
    center = (w / 2.0, h / 2.0)
    # 计算仿射变换矩阵
    rotation0 = cv.getRotationMatrix2D(center, angle, 1)
    # 进行仿射变换
    img_warp0 = cv.warpAffine(img, rotation0, size)

    # 根据定义的三个点进行仿射变换
    src_points = np.array([[0, 0], [0, h - 1], [w - 1, h - 1]], dtype='float32') ##生成原始图像上的三个点（左上角，右上角，左下角）
    dst_points = np.array([[w * 0.11, h * 0.2], [w * 0.15, h * 0.7], [w * 0.81, h * 0.85]], dtype='float32')
    rotation1 = cv.getAffineTransform(src_points, dst_points)
    img_warp1 = cv.warpAffine(img, rotation1, size)

    # 展示结果
    cv.imshow('img_warp0', img_warp0)
    cv.imshow('img_warp1', img_warp1)
    cv.waitKey(0)
    cv.destroyAllWindows()
    #这是一个非常复杂的变换，是CV的重点。也是我项目中的重点内容。
    #说明：对于一张图像而言的坐标系，和我们平时的平面坐标系是有所不同的。我们平时水平方向向右是x轴的正方向，垂直向上是y轴的正方向。
    #但是对于图像而言，它里面的各个像素的位置坐标是：水平方向向右是x轴的正方向，垂直向下是y轴的正方向。因为一张图像的第一个像素[0,0]是这个图像的左上角的第一个像素点。
    #https://zhuanlan.zhihu.com/p/511560729 知乎上讲的挺不错。
#################################################以下是知乎的增补，这个太重要了。
# 在知乎中例5.5 自定义一个变换矩阵，实现图像的平移  
import cv2
import numpy as np
import matplotlib.pyplot as plt
img = cv2.imread(r'C:\Users\25584\Desktop\lenacolor.png')
M = np.float32([[1,0,100], [0,1,200]])    #定义变换矩阵，由于只是移动图像，图像大小没有改变，所以左上矩阵是单位矩阵，右边一列是x轴y轴的原点移动了100、200个像素点。
img_affine1 = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))  #输出图像的大小和原图像大小一样
img_affine2 = cv2.warpAffine(img, M, (800, 800))                    #输出图像变成800x800了。
img_affine3 = cv2.warpAffine(img, M, (400, 400))                    #输出图像变成400x400了。

fig, axes = plt.subplots(1,4, figsize=(12,5), dpi=100)
axes[0].imshow(img[:,:,::-1]), axes[0].set_title('yuan tu ')
axes[1].imshow(img_affine1[:,:,::-1]), axes[1].set_title('img_affine1')#imshow(img_affine1[:,:,::-1])便BRG模式为RGB
axes[2].imshow(img_affine2[:,:,::-1]), axes[2].set_title('img_affine2')
axes[3].imshow(img_affine3[:,:,::-1]), axes[3].set_title('img_affine3')
#这里的M矩阵需要仔细考虑，首先为什么是2*3的变换矩阵，[1,0],[0,1]是单位矩阵[100,200]是平移向量。
######################################################################################
import cv2 as cv
import numpy as np
import sys


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/noobcvqr.png')
    if img is None:
        print('Failed to read noobcvqr.png.')
        sys.exit()

    h, w = img.shape[:2]
    size = (w, h)
    # 读取透视变换前四个角点坐标
    points_path = './data/noobcvqr_points.txt'
    with open(points_path, 'r') as f:
        src_points = np.array([tx.split(' ') for tx in f.read().split('\n')], dtype='float32')#看这里列表的构建形式，是采用了[fo in]的方式。
    #split()：拆分字符串。通过指定分隔符对字符串进行切片，并返回分割后的字符串列表（list）
    #这里有两个split()，第一个是分开\n，第二个是分开" "以获得字符串，不然会提示字符串加上空格的形式无法识别的告警
    print(src_points)
    # 设置透视变换后四个角点坐标
    max_pt = np.max(src_points)
    dst_points = np.array([[0.0, 0.0], [max_pt, 0.0], [0.0, max_pt], [max_pt, max_pt]], dtype='float32')

    print(dst_points)
    # 计算透视变换矩阵
    rotation = cv.getPerspectiveTransform(src_points, dst_points)
    # 透视变换投影
    img_warp = cv.warpPerspective(img, rotation, size)

    # 展示结果
    cv.imshow('Origin', img)
    cv.imshow('img_warp', img_warp)
    cv.waitKey(0)
    cv.destroyAllWindows()
###########################################################################################这里的图像透视变换用于克服图像的拍照等问题造成的图像扭曲的问题，按理说还是比较有用的，但是这个矩阵的获得相对较难。
import cv2 as cv
import numpy as np
import sys
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/dial.png')
    if img is None:
        print('Failed to read dial.png.')
        sys.exit()

    h, w = img.shape[:-1]
    # 计算极坐标在图像中的原点
    center = (w / 2, h / 2)
    # 正极坐标变换
    img_res = cv.warpPolar(img, (300, 600), center, center[0], cv.INTER_LINEAR + cv.WARP_POLAR_LINEAR)
    # 逆极坐标变换
    img_res1 = cv.warpPolar(img_res, (w, h), center, center[0], cv.INTER_LINEAR + cv.WARP_POLAR_LINEAR + cv.WARP_INVERSE_MAP)

    # 展示结果
    cv.imshow('Origin', img)
    cv.imshow('img_res', img_res)
    cv.imshow('img_res1', img_res1)
    cv.waitKey(0)
    cv.destroyAllWindows()
###################################################################这个案例中将圆形的东西转换成长方形的就叫做极坐标变换吗？极坐标系（polar coordinates）是指在平面内
##由极点、极轴和极径组成的坐标系。 在平面上取定一点O，称为极点。 从O出发引一条射线Ox，称为极轴。 再取定一个单位长度，通常规定角度取逆时针方向为正。
import cv2 as cv
import numpy as np
import sys
if __name__ == '__main__':
    # 生成一个黑色图像用于绘制图形
    img = np.zeros((512, 512, 3), dtype='uint8')
    # 绘制圆形
    # 绘制实心圆
    img = cv.circle(img, (50, 50), 25, (255, 255, 255), -1)
    # 绘制空心圆
    img = cv.circle(img, (100, 50), 20, (255, 255, 255), 4)

    # 绘制直线
    img = cv.line(img, (100, 100), (200, 100), (255, 255, 255), 2, cv.LINE_4, 0)

    # 绘制椭圆
    img = cv.ellipse(img, (300, 255), (100, 70), 0, 0, 270, (255, 255, 255), -1)

    # 用一些点近似一个椭圆
    points = cv.ellipse2Poly((200, 400), (100, 70), 0, 0, 360, 2)
    # 使用直线将上述点显示出来
    for i in range(len(points) - 1):
        img = cv.line(img, (points[i][0], points[i][1]), (points[i + 1][0], points[i + 1][1]),
                      (255, 0, 0), 2, cv.LINE_4, 0)
    img = cv.line(img, (points[-1][0], points[-1][1]), (points[0][0], points[0][1]),
                  (255, 0, 0), 2, cv.LINE_4, 0)
    # 绘制矩形
    img = cv.rectangle(img, (50, 400), (100, 450), (0, 255, 0), -1)
    img = cv.rectangle(img, (400, 450, 60, 50), (0, 0, 255), 2)

    # 绘制多边形
    pts = np.array([[350, 83], [463, 90], [500, 171], [421, 194], [338, 141]], dtype='int32')
    img = cv.fillPoly(img, [pts], (255, 0, 0), 8)

    # 添加文字
    img = cv.putText(img, 'Learn OpenCV', (150, 70), 2, 1, (0, 255, 0))
    # 展示结果
    cv.imshow('Image', img)
    cv.waitKey(0)
    cv.destroyAllWindows()
####################################################################这段代码 注意的是类似椭圆是那个虚线画出来的，他是使用CV.LINE()线段画出来的。直接的椭圆是蓝色的。其实不需要后面那部分也可以画出来！！！
import cv2 as cv
import sys
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    noobcv = cv.imread('./images/noobcv.jpg')
    if img is None or noobcv is None:
        print('Failed to read lena.jpg or noobcv.jpg.')
        sys.exit()
    mask = cv.resize(noobcv, (200, 200))
    # 深拷贝
    img1 = img.copy()
    # 浅拷贝
    img2 = img
    # 截取图像的ROI区域
    ROI = img[206: 406, 206: 406]
    # 深拷贝
    ROI_copy = ROI.copy()
    # 浅拷贝
    ROI1 = ROI
    img[206: 406, 206: 406] = mask
    # 展示结果
    cv.imshow('img + noobcv1', img1)
    cv.imshow('img + noobcv2', img2)#把noobcv的截图作为mask然后赋给了原始图像的ROI区域，看深copy是不改变原图的。
    cv.imshow('ROI copy1', ROI_copy)
    cv.imshow('ROI copy2', ROI1)#深浅copy之后赋值，观察ROI区是否有区别，深COPY原图没变化

    # 在图像中绘制圆形
    img = cv.circle(img, (300, 300), 20, (0, 0, 255), -1)#注意机器人那个嘴就是红色圆。
    # 展示结果
    cv.imshow('img + circle1', img1)
    cv.imshow('img + circle2', img2)
    cv.imshow('ROI circle1', ROI_copy)
    cv.imshow('ROI circle2', ROI1)
    cv.imshow("origin picture",img)
    cv.waitKey(0)
    cv.destroyAllWindows()
###################################################深copy就是不改变原图像 很适合后续的使用。注意那个红色的元
import cv2 as cv
import sys
# 构建高斯金字塔
def gauss_image(image):
    # 设置下采样次数
    level = 3
    img = image.copy()
    gauss_images = []
    gauss_images.append(G0)
    cv.imshow('Gauss_0', G0)
    for i in range(level):
        dst = cv.pyrDown(img)
        gauss_images.append(dst)
        cv.imshow('Gauss_{}'.format(i + 1), dst)
        img = dst.copy()
    return gauss_images

# 构建拉普拉斯金字塔
def laplian_image(image):
    gauss_images = gauss_image(image)
    level = len(gauss_images)
    for i in range(level-1, 0, -1):
        expand = cv.pyrUp(gauss_images[i], dstsize=gauss_images[i-1].shape[:2])#step1.这里根本不是拉普拉斯金子塔，这里是上采样
        lpls = cv.subtract(gauss_images[i-1], expand)#step2 将上采样与高斯金字塔i-1相减。
        cv.imshow('Laplacian_{}'.format(level-i), lpls)
    # 构建最顶层，需要先进行下采样、再进行上采样，！！！！！！！！！！！！！！！！！！！这里最重要，是拉普拉斯的主要算法。
    expand = cv.pyrUp(cv.pyrDown(gauss_images[3]), dstsize=gauss_images[3].shape[:2])
    lpls = cv.subtract(gauss_images[3], expand)
    cv.imshow('Laplacian_{}'.format(0), lpls)
#对于我来说，为什么会这样写，laplacian_0需要写出来，因为并没有gauss[4]这个数据
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    G0 = cv.imread('./images/lena.jpg')
    if G0 is None:
        print('Failed to read lena.jpg.')
        sys.exit()

    laplian_image(G0)
    cv.waitKey(0)
    cv.destroyAllWindows()
###############################################注意这里是完整的程序了，不管是高斯金字塔还是拉普拉斯金字塔的第一个写出来，剩下的参与到循环中去。最终的laplacian看起来也没有觉得
import cv2 as cv
import numpy as np
import sys

def call_backl_brightness(x):
    global value, img, img1
    value = cv.getTrackbarPos('brightness', 'Brighter')#函数cvGetTrackbarPos返回指定trackbar的当前位置
    img1 = np.uint8(np.clip((value / 100 * img), 0, 255))#numpy中的clip()函数用于将数组中的元素控制在一个给定的范围内，给定需要控制的范围的上下边界，clip函数将所有小于下边界的数值全部改为下边界， 将大于上边界的数值全部改为上边界。

if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    img1 = img.copy()
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    cv.namedWindow('Brighter')
    # 设置滑动条的初始值为100
    value = 100
    # 创建滑动条
    cv.createTrackbar('brightness', 'Brighter', value, 300, call_backl_brightness)#call_backl_brightness这里的作用是滑块在移动时调用的函数指针。

    while True:
        cv.imshow('Brighter', img1)
        if cv.waitKey(1) == ord('q'):
            break
    cv.destroyAllWindows()
#这里的cv.createTrackbar('brightness', 'Brighter'......)和cv.getTrackbarPos('brightness', 'Brighter')里面两个参数终都是图像名称和标签名称。通过这两个名称使他们对应起来。
###################################我觉得这里的奇妙的是这里def call_backl_brightness(x)，里面有个X，后面貌似没有使用到，其实他是被调用了这个X，如果没有就会报错。
def A(B):
    B(32)
def C(w):
    print(w)
A(C)
是否这样理解A(C)-----C是B的实参 因此得到C(32)-----执行C（W）的函数，print(32)-----------结果显示32
###########################################################################################################
import cv2 as cv
import sys
def draw(event, x, y,flags,param):
    global img, pre_pts

    # 鼠标右键按下
    if event == cv.EVENT_RBUTTONDOWN:
        print('请点击鼠标左键进行轨迹的绘制。')

    # 鼠标左键按下
    if event == cv.EVENT_LBUTTONDOWN:
        pre_pts = (x, y)
        print('轨迹起始坐标为：{}, {}'.format(x, y))

    # 鼠标移动
    if event == cv.EVENT_MOUSEMOVE and flags == cv.EVENT_FLAG_LBUTTON:#cv.EVENT_MOUSEMOVE鼠标移动，cv.EVENT_FLAG_LBUTTON按住鼠标左键拖曳
        pts = (x, y)
        img = cv.line(img, pre_pts, pts, (0, 0, 255), 2, 5,0)倒数第一个是默认0，倒数第二个是线性。
        pre_pts = pts
        cv.imshow('image', img)
if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    img = cv.imread('./images/lena.jpg')
    img1 = img.copy()
    if img is None:
        print('Failed to read lena.jpg.')
        sys.exit()
    pre_pts = -1, -1
    cv.imshow('image', img1)
    cv.setMouseCallback('image', draw)#本小结中的鼠标调用函数。
    cv.waitKey(0)
    cv.destroyAllWindows()
######################################################这里调用draw时候把draw()后面的括号都省了，里面的调用属于底层的调用。底层代码都被封装了，我在写draw()函数的时候，要求是这5个函数，连顺序都不变。
######
######       CHARPTER 4 
######
######################################################
import cv2 as cv
import sys
import numpy as np

# 设置不显示科学计数法，显示普通数字
np.set_printoptions(suppress=True)
if __name__ == '__main__':
    # 以灰度方式读取图像
    image = cv.imread('./images/apple.jpg', 0)
    # 判断是否读取成功
    if image is None:
        print("Failed to read apple.jpg.")
        sys.exit()
    # 对图像进行直方图计算
    hist = cv.calcHist([image], [0], None, [256], [0, 256])
    # 输出结果
    print('统计灰度直方图为：\n{}'.format(hist))
    print(hist.shape)
###########################################################################记录出来是列表的形式，后面需要画图。
import cv2 as cv
import numpy as np
import sys
# 设定bins的数目
bins = np.arange(256).reshape(256, 1)

def draw_gray_histogram(image):
    # 创建一个全0矩阵以绘制直方图
    new = np.zeros((image.shape[0], 256, 3))#image.shape[0]图片高度
    # 对图像进行直方图计算
    hist_item = cv.calcHist([image], [0], None, [256], [0, 256])
    # 对直方图进行归一化，我们将在4.3.1节进行详细讲解
    cv.normalize(hist_item, hist_item, 0, 255, cv.NORM_MINMAX)
    hist = np.int32(np.around(hist_item))#np.around()是将后面的值转换成整数，该函数遵循四舍五入原则，但是需要特别注意的是，当整数部分以0结束时，round函数一律是向下取整。
    for x, y in enumerate(hist):#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。索引是关键字
        cv.line(new, (x, 0), (x, y[0]), (255, 255, 255))
    print(x)
    # 由于绘制时是从顶部开始绘制，因此需要将矩阵进行翻转
    #result = cv.flip(new, 0)#flip(new,0)表示沿X轴方向对称。
    result=new
    return result
def draw_bgr_histogram(image):
    # 创建一个3通道的全0矩阵以绘制直方图
    new = np.zeros((image.shape[0], 256, 3))
    # 声明BGR三种颜色
    bgr = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
    for i, col in enumerate(bgr):#这里的bgr其实只有三个值，分别代表红绿蓝，三种颜色分别画图。这里告诉了我们红黄绿三色是怎么作图的。
        hist_item = cv.calcHist([image], [i], None, [256], [0, 256])
        cv.normalize(hist_item, hist_item, 0, 255, cv.NORM_MINMAX)
        hist = np.int32(np.around(hist_item))
        hist = np.int32(np.column_stack((bins, hist)))#这是将两个矩阵横着合并，还有一个np.row_stack是将矩阵纵向合并。
        cv.polylines(new, [hist], False, col)
    result = cv.flip(new, 0)#都需要
    return result

if __name__ == '__main__':
    # 读取图像flower.jpg
    img = cv.imread('./images/flower.jpg')
    # 判断是否读取成功
    if img is None:
        print("Failed to read flower.jpg.")
        sys.exit()
    # 将图片转为灰度模式
    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
    # 计算并绘制灰度图像直方图和BGR图像直方图
    gray_histogram = draw_gray_histogram(gray)
    bgr_histogram = draw_bgr_histogram(img)

    cv.imshow('Origin Image', img)
    cv.imshow('Gray Histogram', gray_histogram)
    cv.imshow('BGR Histogram', bgr_histogram)
    cv.waitKey(0)
    cv.destroyAllWindows()
######################################################################################分别使用了line和polyline画了直方图。还画了灰度图和彩色图的直方图。
import cv2 as cv
from matplotlib import pyplot as plt
import sys
if __name__ == '__main__':
    # 以灰度模式读取图像
    img = cv.imread('./images/flower.jpg', 0)
    # 判断图片是否读取成功
    if img is None:
        print('Failed to read flower.jpg.')
        sys.exit()

    # 绘制直方图并展示
    _, _, _ = plt.hist(x=img.ravel(), bins=256, range=[0, 256])
    cv.imshow('image', img)
    plt.show()
    cv.waitKey(0)
    cv.destroyAllWindows()
###################################需要注意的是ravel()函数可以将图像多维数组拉成一维的，bins的作用bins取值整数时是是用来做X轴的多少等分。
import cv2 as cv
from matplotlib import pyplot as plt
import sys


if __name__ == '__main__':
    # 读取图像
    img = cv.imread('./images/flower.jpg')
    # 判断图像是否读取成功
    if img is None:
        print('Failed to read flower.jpg.')
        sys.exit()
    # 绘制直方图并展示
    color = ('b', 'g', 'r')
    #color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
    for i, col in enumerate(color):
        hist_item = cv.calcHist([img], [i], None, [256], [0, 256])#[i]形成图像索引
        plt.plot(hist_item, color=col)
    cv.imshow('image', img)
    plt.show()
    cv.waitKey(0)
    cv.destroyAllWindows()
################################################试了不能使用color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]，因为这里的plt.plot无法识别数字形式。
import numpy as np
import cv2 as cv
import sys

if __name__ == '__main__':
    # 构建一个HSV格式颜色地图，然后将其转换为BGR格式
    hsv_map = np.zeros((180, 256, 3), dtype=np.uint8)

    h, s = np.indices(hsv_map.shape[:2])#np.indices()函数返回一个由数组索引构成的数组，以便你轻松地生成包含任所需要形状和大小的数组。
    # 可以通过参数设置起点，若不设置则默认从0开始。
    #如果没有这里的indices()的转换，h,s分别等于int 180和256 ,所以 我觉得这里是增加了维度。
    #print(h.shape)
    #print(h)
    #print(s.shape)
    #print(s)
    hsv_map[:, :, 0] = h #brg图中一般是b ，这里是指h通道
    hsv_map[:, :, 1] = s #brg图中一般是g，这里指s通道
    hsv_map[:, :, 2] = 255 #brg图中一般是r，这里是指V通道，V通道所有值都赋255，
    hsv_map = cv.cvtColor(hsv_map, cv.COLOR_HSV2BGR)
   # print(f"hsv_map是这样子{hsv_map}")

    # 读取图像road.jpg
    image = cv.imread('./images/road.jpg')
    # 判断是否读取成功
    if image is None:
        print("Failed to read road.jpg.")
        sys.exit()
    # 将图片由BGR格式转换成HSV格式
    image_hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)
    # binggan1=image[:, :, 0]
    # print(f"饼干是{binggan1}")

    # 计算2D直方图
    image_hist = cv.calcHist([image_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
    print('2D直方图计算结果：\n{}'.format(image_hist))
    image_hist = np.clip(image_hist*0.05 , 0, 1)
    result = hsv_map * image_hist[:, :, np.newaxis] / 255.0#hsv_map已经转换成了BGR格式，image_hist是个2D的直方图，他们居然相乘了。这里的意义是构建了2D的直方图。因为没有直接表示2D直方图的方法。
#[:, :, np.newaxis]意思是给数组新增一个维度，
    # a = np.array([1, 2, 3])
    # b = a[np.newaxis, :]结果为b=[[1,2 ,3]]
    # c = a[:, np.newaxis]结果为[[1]
    #                           [2]
    #                          [3]]
    # 展示结果
    cv.imshow('Origin Image', image)
    cv.imshow('Hsv Map', hsv_map)
    cv.imshow('2D Hist', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
#做了个非常恶心的操作，明明可以构建一个BGR的图片的，为什么要构建一个HSV，然后再转成BGR呢？
#这里的h,s都是一个二维的数组，如书中所示，h是从上到下1——179，s是从左到右0-255.这是HSV不同于RGB的特征。
####################知识点挺多的，这里构建了一个2D的直方图，比较复杂。需要记忆！我感觉实际中的2D的直方图的显示应该用plt.imshow()函数来实现。
import cv2 as cv
from matplotlib import pyplot as plt
import sys

if __name__ == '__main__':
    # 读取图像road.jpg
    image = cv.imread('./images/road.jpg')
    # 判断图片是否读取成功
    if image is None:
        print('Failed to read image.')
        sys.exit()
    # 将图像的颜色空间从BGR转为HSV
    image_hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)
    
    # 计算2D直方图
    image_hist = cv.calcHist([image_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
    # 展示图像及直方图结果
    cv.imshow('Origin Image', image)
    plt.imshow(image_hist, interpolation='nearest')
    plt.show()
    cv.waitKey(0)
    cv.destroyAllWindows()
########################################################注意这里显示的是hsv图像的
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
import sys
if __name__ == '__main__':
    # 对数组进行归一化
    data = np.array([2.0, 8.0, 10.0])
    # 绝对值求和归一化
    data_L1 = cv.normalize(data, None, 1.0, 0.0, cv.NORM_L1)
    # 模长归一化
    data_L2 = cv.normalize(data, None, 1.0, 0.0, cv.NORM_L2)
    # 最大值归一化
    data_Inf = cv.normalize(data, None, 1.0, 0.0, cv.NORM_INF)
    # 偏移归一化
    data_L2SQR = cv.normalize(data, None, 1.0, 0.0, cv.NORM_MINMAX)
    # 展示结果
    print('绝对值求和归一化结果为：\n{}'.format(data_L1))
    print('模长归一化结果为：\n{}'.format(data_L2))
    print('最大值归一化结果为：\n{}'.format(data_Inf))
    print('偏移归一化结果为：\n{}'.format(data_L2SQR))

    # 对图像直方图进行归一化
    # 读取图像
    image = cv.imread('./images/apple.jpg')
    # 判断图片是否读取成功
    if image is None:
        print('Failed to read apple.jpg.')
        sys.exit()

    # 将图像转为灰度图像
    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    # 对图像进行直方图计算
    hist_item = cv.calcHist([gray_image], [0], None, [256], [0, 256])

    # 对直方图进行绝对值求和归一化
    image_L1 = cv.normalize(hist_item, None, 1, 0, cv.NORM_L1)
    # 对直方图进行最大值归一化
    image_Inf = cv.normalize(hist_item, None, 1, 0, cv.NORM_INF)
    # 展示结果
    plt.plot(image_L1)
    plt.show()
    plt.plot(image_Inf)
    plt.show()
#################################################简简单单的先求直方图的list，然后再归一化，最后画图三步曲。
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
import sys

def normalize_image(path):
    # 以灰度方式读取图像
    image = cv.imread(path, 0)
    # 判断图片是否读取成功
    if image is None:
        print('Failed to read image.')
        sys.exit()
    # 绘制直方图
    plt.hist(image.ravel(), 256, [0, 256])
    plt.title(path.split('/')[-1])
    plt.show()
    # 计算图像直方图
    image_hist = cv.calcHist([image], [0], None, [256], [0, 256])
    # 进行归一化
    normalize_result = np.ones(image_hist.shape, dtype=np.float32)#这里有dst，讲归一化的时候所有的dst都是NONE，这里的作用是将两个图像具有相同的尺寸，zeros和ones结果是相同的。
    cv.normalize(image_hist, dst=normalize_result, alpha=1, beta=0, norm_type=cv.NORM_MINMAX)
    return normalize_result

def compare_hist(image1_path, image2_path):
    image1 = normalize_image(image1_path)
    image2 = normalize_image(image2_path)
    # 进行图像直方图比较
    return round(cv.compareHist(image1, image2, method=cv.HISTCMP_CORREL), 2)#2是比较方法的标识。

if __name__ == '__main__':
    img1_path = './images/Compare_Hist_1.jpg'
    img2_path = './images/Compare_Hist_2.jpg'
    img3_path = './images/Compare_Hist_3.jpg'
    img4_path = './images/Compare_Hist_4.jpg'

    print('Compare_Hist_1.jpg与Compare_Hist_2.jpg的相似性为：%s' % (compare_hist(img1_path, img2_path)))
    print('Compare_Hist_3.jpg与Compare_Hist_4.jpg的相似性为：%s' % (compare_hist(img3_path, img4_path)))
########################################################语言很简练，函数相互嵌套。
import cv2 as cv
from matplotlib import pyplot as plt
import sys

if __name__ == '__main__':
    # 读取图像
    image = cv.imread('./images/equalizeHist.jpg', 0)
    # 判断图片是否读取成功
    if image is None:
        print('Failed to read equalizeHist.jpg.')
        sys.exit()
    # 绘制原图直方图
    plt.hist(image.ravel(), 256, [0, 256])
    plt.title('Origin Image')
    plt.show()
    # 进行均衡化并绘制直方图
    image_result = cv.equalizeHist(image)
    plt.hist(image_result.ravel(), 256, [0, 256])
    plt.title('Equalized Image')
    plt.show()
    # 展示均衡化前后的图片
    cv.imshow('Origin Image', image)
    cv.imshow('Equalized Image', image_result)

    cv.waitKey(0)
    cv.destroyAllWindows()
#############################################直方图均衡 可以增加灰度的分布，以增加图片的分辨效果。
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
import sys

if __name__ == '__main__':
    # 读取图像
    image1 = cv.imread('./images/Hist_Match.png')
    image2 = cv.imread('./images/equalLena.png')
    # 判断图片是否读取成功
    if image1 is None or image2 is None:#看这里两张图片一起读的情况。
        print('Failed to read Hist_Match.png or equalLena.png.')
        sys.exit()

    # 计算两张图像的直方图
    hist_image1 = cv.calcHist([image1], [0], None, [256], [0, 256])
    hist_image2 = cv.calcHist([image2], [0], None, [256], [0, 256])
    # 对直方图进行归一化
    hist_image1 = cv.normalize(hist_image1, None, norm_type=cv.NORM_L1)#直方图的归一化的原因，我需要认真记录一下，我们完成了对图像灰度值的统计工作，并成功绘制了图像的直方图。由于统计的灰度值数目与图像的尺寸具有直接关系，
    """ 因此如果以灰度值数目作为最终统计结果，那么一张图像与它经过尺寸缩放后的图像的直方图将会有巨大的差异。直方图可以用来表示图像的明亮程度，从理论上讲，这两张图像将具有大致相似的直方图分布特性，因此用灰度值的数目作为统计结果具有
    定的局限性。图像的灰度值统计的主要目的就是查看某个灰度值在所有像素中所占的比例,你可以用每个灰度值的像素数目占一幅图像中所有像素的比例来表示某个灰度值数目的多少,即将统计结果除以图像中的像素个数。这种方式可以保证每个灰度值的统计结果都是0%~100%的数据，
     从而实现统计结果的归一化。但这种方式存在一个弊端，就是在数据类型为 uint8 的图像中，灰度值有256个等级，平均每个像素的灰度值所占比例为 0.39%，这个比例非常低。因此，为了更直观地绘制直方图,你需要将比例扩大一定的倍数。另一种常用的归一化方式是寻找统计结果中的最大数值，
    把所有结果除以这个最大的数值，以将所有数据都归一化到0~1。"""
    hist_image2 = cv.normalize(hist_image2, None, norm_type=cv.NORM_L1)

    # 计算两张图像直方图的累计概率
    hist1_cdf = np.zeros((256, ))
   # print(hist1_cdf)
    hist2_cdf = np.zeros((256, ))
    hist1_cdf[0] = 0
    hist2_cdf[0] = 0
    for i in range(1, 256):
        hist1_cdf[i] = hist1_cdf[i - 1] + hist_image1[i]
        hist2_cdf[i] = hist2_cdf[i - 1] + hist_image2[i]

    # 构建累计概率误差矩阵
    diff_cdf = np.zeros((256, 256))
    for k in range(256):
        for j in range(256):
            diff_cdf[k][j] = np.fabs((hist1_cdf[k] - hist2_cdf[j]))#构建误差矩阵的作用是为了映射。
            #numpy.fabs ()函数用于逐元素计算绝对值。. 此函数以arr返回数据的绝对值 (正值)。. 它总是以浮点数返回绝对值。
    print(diff_cdf.shape)#这是个（256，256）的list

    # 生成LUT映射表
    lut = np.zeros((256, ), dtype='uint8')
    for m in range(256):
        # 查找源灰度级为i的映射灰度和i的累计概率差值最小的规定化灰度
        min_val = diff_cdf[m][0]
        index = 0
        for n in range(256):
            if min_val > diff_cdf[m][n]:
                min_val = diff_cdf[m][n]
                index = n#找到最小的n值
        lut[m] = index#把找到最小的n赋给了lut[0]，然后一次赋值。完成lut[m]的编写。
    print(lut)
    result = cv.LUT(image1, lut)

    # 展示结果
    cv.imshow('Origin Image1', image1)
    cv.imshow('Origin Image2', image2)
    cv.imshow('Result', result)
    _, _, _ = plt.hist(x=image1.ravel(), bins=256, range=[0, 256])
    plt.show()
    _, _, _ = plt.hist(x=image2.ravel(), bins=256, range=[0, 256])
    plt.show()
    _, _, _ = plt.hist(x=result.ravel(), bins=256, range=[0, 256])
    plt.show()

    cv.waitKey(0)
    cv.destroyAllWindows()
##########################################################怎么理解这里的 diff_cdf，他的shape（(256, 256)），又怎么理解这个LUT （256，）从左到右正好是递增的呢？
##########################################################从左到右正好是递增的呢？这个问题 我可以理解了，因为就是累计概率，从左到右就是递增的关系。
#######################################################关于（256，256）我觉得可以重写这个算法，以实现两个(256,)的比较。
import cv2 as cv
import sys


if __name__ == '__main__':
    # 读取图像并判断是否读取成功
    origin_image = cv.imread('./images/calcBackProject.jpg')
    template_image = cv.imread('./images/calcBackProject_template.jpg')
    if origin_image is None or template_image is None:
        print('Failed to read calcBackProject.jpg or calcBackProject_template.jpg.')
        sys.exit()
    # 分别将其颜色空间从BGR转换到HSV
    origin_hsv = cv.cvtColor(origin_image, cv.COLOR_BGR2HSV)
    template_hsv = cv.cvtColor(template_image, cv.COLOR_BGR2HSV)

    # 计算模板图像的直方图
    template_hist = cv.calcHist([template_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])

    # 对模板图像的直方图进行偏移归一化处理
    cv.normalize(template_hist, template_hist, 0, 255, cv.NORM_MINMAX)
    # 计算直方图的反向投影
    result = cv.calcBackProject([origin_hsv], [0, 1], template_hist, [0, 180, 0, 256], 1)
    # 显示图像
    cv.imshow('Origin Image', origin_image)
    cv.imshow('Template Image', template_image)
    cv.imshow('calcBackProject_result', result)
    cv.waitKey(0)
    cv.destroyAllWindows()
################################################反向投影的作用是使用直方图的方式模板匹配cv.calcBackProject()。
